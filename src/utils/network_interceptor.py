#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Pinterestç½‘ç»œè¯·æ±‚æ‹¦æˆªå™¨

ç”¨äºç›‘å¬å’Œåˆ†æPinteresté¡µé¢çš„ç½‘ç»œè¯·æ±‚ï¼Œè¯†åˆ«APIç«¯ç‚¹å’Œå‚æ•°ç»“æ„
"""

import json
import os
import time
import threading
import asyncio
from datetime import datetime
from typing import Dict, List, Optional, Callable, Any, Union
from urllib.parse import urlparse, parse_qs
from collections import deque

from loguru import logger
from patchright.sync_api import sync_playwright, Page, BrowserContext, Response, Request
from tqdm import tqdm

from ..core import config
# Browser import removed - using BrowserManager instead


class PinDataExtractor:
    """Pinterest Pinæ•°æ®æå–å™¨

    ä»APIå“åº”ä¸­æå–ç»“æ„åŒ–çš„Pinæ•°æ®ï¼Œæ”¯æŒå¤šç§Pinterest APIæ ¼å¼
    """

    @staticmethod
    def extract_pins_from_response(json_data: Dict) -> List[Dict]:
        """ä»APIå“åº”ä¸­æå–Pinæ•°æ®åˆ—è¡¨

        Args:
            json_data: Pinterest APIå“åº”çš„JSONæ•°æ®

        Returns:
            æå–çš„Pinæ•°æ®åˆ—è¡¨
        """
        if not isinstance(json_data, dict):
            return []

        pins = []

        # å°è¯•å¤šç§å¯èƒ½çš„Pinæ•°æ®ä½ç½®
        possible_paths = [
            # æœç´¢APIå“åº”æ ¼å¼
            ["resource_response", "data"],
            ["resource_response", "data", "results"],
            # GraphQLå“åº”æ ¼å¼ - Pinè¯¦æƒ…é¡µç›¸å…³æ¨è
            ["data", "v3RelatedPinsForPinSeoQuery", "data", "connection", "edges"],
            # å…¶ä»–GraphQLæ ¼å¼
            ["data", "node", "pins"],
            ["data", "viewer", "pins"],
            # ç›´æ¥ç»“æœæ ¼å¼
            ["results"],
            ["data", "results"],
            ["pins"],
            ["data", "pins"],
            # Pinè¯¦æƒ…é¡µç›¸å…³æ¨èæ ¼å¼
            ["resource_response", "data", "related_pins"],
            ["data", "related_pins"],
        ]

        for path in possible_paths:
            extracted_pins = PinDataExtractor._extract_from_path(json_data, path)
            if extracted_pins:
                pins.extend(extracted_pins)
                logger.debug(f"ä»è·¯å¾„ {' -> '.join(path)} æå–åˆ° {len(extracted_pins)} ä¸ªPin")

        # å»é‡å¤„ç†ï¼ˆåŸºäºPin IDï¼‰
        unique_pins = {}
        for pin in pins:
            pin_id = pin.get('id')
            if pin_id and pin_id not in unique_pins:
                unique_pins[pin_id] = pin

        result = list(unique_pins.values())
        return result

    @staticmethod
    def _extract_from_path(data: Dict, path: List[str]) -> List[Dict]:
        """ä»æŒ‡å®šè·¯å¾„æå–Pinæ•°æ®

        Args:
            data: JSONæ•°æ®
            path: æ•°æ®è·¯å¾„

        Returns:
            Pinæ•°æ®åˆ—è¡¨
        """
        current_data = data
        for key in path:
            if isinstance(current_data, dict) and key in current_data:
                current_data = current_data[key]
            else:
                return []

        if isinstance(current_data, list):
            # éªŒè¯æ˜¯å¦ä¸ºPinæ•°æ®
            valid_pins = []
            for item in current_data:
                # å¤„ç†GraphQL edgesæ ¼å¼
                if isinstance(item, dict) and "node" in item:
                    # GraphQL edgeæ ¼å¼: {"node": {"__typename": "Pin", ...}}
                    pin_data = item["node"]
                    if isinstance(pin_data, dict) and PinDataExtractor._is_valid_pin(pin_data):
                        normalized_pin = PinDataExtractor._normalize_pin_data(pin_data)
                        valid_pins.append(normalized_pin)
                # å¤„ç†ç›´æ¥Pinæ ¼å¼
                elif isinstance(item, dict) and PinDataExtractor._is_valid_pin(item):
                    normalized_pin = PinDataExtractor._normalize_pin_data(item)
                    valid_pins.append(normalized_pin)
            return valid_pins

        return []

    @staticmethod
    def _normalize_pin_id(pin_id: str) -> str:
        """æ ‡å‡†åŒ–Pin IDæ ¼å¼ï¼Œå¤„ç†Base64ç¼–ç çš„GraphQL ID

        Args:
            pin_id: åŸå§‹Pin ID

        Returns:
            æ ‡å‡†åŒ–åçš„Pin ID (çº¯æ•°å­—æ ¼å¼)
        """
        if not pin_id:
            return ""

        # æ£€æŸ¥æ˜¯å¦ä¸ºBase64ç¼–ç çš„GraphQL ID (ä»¥UGluå¼€å¤´)
        if pin_id.startswith('UGlu'):
            try:
                import base64
                decoded = base64.b64decode(pin_id).decode('utf-8')
                if decoded.startswith('Pin:'):
                    # å»æ‰'Pin:'å‰ç¼€ï¼Œè¿”å›çº¯æ•°å­—ID
                    return decoded[4:]
            except Exception as e:
                logger.error(f"è§£ç Pin IDå¤±è´¥: {e}")

        return pin_id

    @staticmethod
    def _is_valid_pin(data: Dict) -> bool:
        """éªŒè¯æ•°æ®æ˜¯å¦ä¸ºæœ‰æ•ˆçš„Pinæ•°æ®

        Args:
            data: å¾…éªŒè¯çš„æ•°æ®

        Returns:
            æ˜¯å¦ä¸ºæœ‰æ•ˆPinæ•°æ®
        """
        # å¿…é¡»æœ‰æœ‰æ•ˆçš„Pin ID
        pin_id = data.get('id') or data.get('entityId', '')
        if not pin_id:
            return False

        # æ ‡å‡†åŒ–Pin IDå¹¶éªŒè¯æ˜¯å¦ä¸ºæ•°å­—
        normalized_id = PinDataExtractor._normalize_pin_id(str(pin_id))
        if not normalized_id or not normalized_id.isdigit():
            return False

        # å¿…é¡»åŒ…å«å›¾ç‰‡ä¿¡æ¯ï¼ˆæ”¯æŒGraphQLæ ¼å¼çš„imageSpec_*å­—æ®µï¼‰
        has_images = (
            data.get('images') or
            data.get('image') or
            data.get('image_signature') or
            any(key.startswith('imageSpec_') for key in data.keys()) or  # GraphQLæ ¼å¼
            (data.get('__typename') == 'Pin' and 'images' in data)
        )

        if not has_images:
            return False

        # æ£€æŸ¥GraphQL Pinæ ¼å¼
        if data.get('__typename') == 'Pin':
            return True

        # æ£€æŸ¥ä¼ ç»Ÿæ ¼å¼çš„å…³é”®å­—æ®µ
        required_fields = ['title', 'description', 'url']
        return any(field in data for field in required_fields)

    @staticmethod
    def _normalize_pin_data(raw_pin: Dict) -> Dict:
        """æ ‡å‡†åŒ–Pinæ•°æ®æ ¼å¼

        Args:
            raw_pin: åŸå§‹Pinæ•°æ®

        Returns:
            æ ‡å‡†åŒ–åçš„Pinæ•°æ®
        """
        # å†³ç­–ç†ç”±ï¼šç»Ÿä¸€æ•°æ®æ ¼å¼ï¼Œä¾¿äºåç»­å¤„ç†å’Œå­˜å‚¨
        normalized = {
            "id": "",
            "title": "",
            "description": "",
            "image_urls": {},
            "largest_image_url": "",
            "url": "",
            "creator": {},
            "stats": {},
            "board": {},
            "created_at": "",
            "source_link": "",
            "categories": [],
            "extracted_at": datetime.now().isoformat()
        }

        # æå–Pin ID (ä¼˜å…ˆä½¿ç”¨entityIdï¼Œè¿™æ˜¯çœŸå®çš„æ•°å­—ID)
        pin_id = raw_pin.get("entityId") or raw_pin.get("id", "")
        normalized["id"] = str(pin_id) if pin_id else ""

        # æå–æ ‡é¢˜å’Œæè¿°
        normalized["title"] = raw_pin.get("title", "")
        normalized["description"] = raw_pin.get("description", "")

        # æå–å›¾ç‰‡URLs
        image_urls = PinDataExtractor._extract_image_urls(raw_pin)
        normalized["image_urls"] = image_urls
        normalized["largest_image_url"] = PinDataExtractor._get_largest_image_url(image_urls)

        # æå–Pin URL
        pin_id = normalized["id"]
        if pin_id:
            normalized["url"] = f"https://www.pinterest.com/pin/{pin_id}/"
        elif "url" in raw_pin:
            normalized["url"] = raw_pin["url"]

        # æå–åˆ›å»ºè€…ä¿¡æ¯
        if "pinner" in raw_pin:
            creator_data = raw_pin["pinner"]
            normalized["creator"] = {
                "id": creator_data.get("id", ""),
                "username": creator_data.get("username", ""),
                "full_name": creator_data.get("full_name", ""),
                "image_url": creator_data.get("image_medium_url", "")
            }

        # æå–ç»Ÿè®¡ä¿¡æ¯
        stats = {}
        if "like_count" in raw_pin:
            stats["likes"] = raw_pin["like_count"]
        if "repin_count" in raw_pin:
            stats["saves"] = raw_pin["repin_count"]
        if "comment_count" in raw_pin:
            stats["comments"] = raw_pin["comment_count"]
        normalized["stats"] = stats

        # æå–Boardä¿¡æ¯
        if "board" in raw_pin:
            board_data = raw_pin["board"]
            normalized["board"] = {
                "id": board_data.get("id", ""),
                "name": board_data.get("name", ""),
                "url": board_data.get("url", "")
            }

        # æå–å…¶ä»–å…ƒæ•°æ®
        if "created_at" in raw_pin:
            normalized["created_at"] = raw_pin["created_at"]
        if "link" in raw_pin:
            normalized["source_link"] = raw_pin["link"]

        return normalized

    @staticmethod
    def _extract_image_urls(pin_data: Dict) -> Dict[str, str]:
        """æå–Pinçš„å›¾ç‰‡URLs

        Args:
            pin_data: Pinæ•°æ®

        Returns:
            å›¾ç‰‡URLå­—å…¸ï¼Œé”®ä¸ºå°ºå¯¸ï¼Œå€¼ä¸ºURL
        """
        image_urls = {}

        # å¤„ç†GraphQLæ ¼å¼çš„imageSpec_*å­—æ®µï¼ˆæ–°æ ¼å¼ï¼‰
        for key, value in pin_data.items():
            if key.startswith("imageSpec_") and isinstance(value, dict) and "url" in value:
                size_key = key.replace("imageSpec_", "")
                if size_key == "orig":
                    image_urls["original"] = value["url"]
                else:
                    image_urls[size_key] = value["url"]

        # å¤„ç†imageså­—æ®µï¼ˆæ ‡å‡†æ ¼å¼ï¼‰
        if "images" in pin_data and isinstance(pin_data["images"], dict):
            for size_key, img_data in pin_data["images"].items():
                if isinstance(img_data, dict) and "url" in img_data:
                    if size_key == "orig":
                        image_urls["original"] = img_data["url"]
                    else:
                        # æå–å°ºå¯¸ä¿¡æ¯
                        size = size_key.replace("x", "")
                        image_urls[size] = img_data["url"]

        # å¤„ç†å•ä¸ªimageå­—æ®µ
        elif "image" in pin_data:
            image_data = pin_data["image"]
            if isinstance(image_data, dict):
                # å¤„ç†å¤šå°ºå¯¸æ ¼å¼
                for size_key, url in image_data.items():
                    if isinstance(url, str) and url.startswith("http"):
                        image_urls[size_key] = url
            elif isinstance(image_data, str):
                image_urls["default"] = image_data

        return image_urls

    @staticmethod
    def _get_largest_image_url(image_urls: Dict[str, str]) -> str:
        """è·å–æœ€å¤§å°ºå¯¸çš„å›¾ç‰‡URL

        Args:
            image_urls: å›¾ç‰‡URLå­—å…¸

        Returns:
            æœ€å¤§å°ºå¯¸å›¾ç‰‡çš„URL
        """
        if not image_urls:
            return ""

        # ä¼˜å…ˆçº§é¡ºåºï¼šoriginal > æ•°å­—å°ºå¯¸ï¼ˆä»å¤§åˆ°å°ï¼‰> default
        if "original" in image_urls:
            return image_urls["original"]

        # æŒ‰æ•°å­—å°ºå¯¸æ’åº
        numeric_sizes = []
        for size_key, url in image_urls.items():
            if size_key.isdigit():
                numeric_sizes.append((int(size_key), url))

        if numeric_sizes:
            numeric_sizes.sort(reverse=True)
            return numeric_sizes[0][1]

        # è¿”å›ä»»æ„å¯ç”¨çš„URL
        return next(iter(image_urls.values()))


class CredentialExtractor:
    """Pinterestè®¤è¯å‡­è¯æå–å™¨

    ä»ç½‘ç»œè¯·æ±‚ä¸­æå–è®¤è¯ä¿¡æ¯ï¼Œä¸ºåç»­HTTP APIè°ƒç”¨åšå‡†å¤‡
    """

    def __init__(self):
        self.credentials = {
            "cookies": {},
            "csrf_token": "",
            "headers": {},
            "user_agent": "",
            "app_version": "",
            "extracted_at": ""
        }
        self._lock = threading.Lock()

    def extract_from_request(self, request_data: Dict) -> None:
        """ä»è¯·æ±‚æ•°æ®ä¸­æå–è®¤è¯ä¿¡æ¯

        Args:
            request_data: è¯·æ±‚æ•°æ®å­—å…¸
        """
        with self._lock:
            headers = request_data.get("headers", {})

            # æå–Cookie
            cookie_header = headers.get("cookie", "")
            if cookie_header:
                self._parse_cookies(cookie_header)

            # æå–CSRF Token
            csrf_token = headers.get("x-csrftoken", "")
            if csrf_token:
                self.credentials["csrf_token"] = csrf_token

            # æå–é‡è¦çš„è¯·æ±‚å¤´
            important_headers = [
                "x-pinterest-appstate",
                "x-requested-with",
                "x-pinterest-source-url",
                "x-pinterest-pws-handler",
                "accept",
                "accept-language",
                "referer"
            ]

            for header_name in important_headers:
                header_value = headers.get(header_name, "")
                if header_value:
                    self.credentials["headers"][header_name] = header_value

            # æå–User-Agent
            user_agent = headers.get("user-agent", "")
            if user_agent:
                self.credentials["user_agent"] = user_agent

            # æ›´æ–°æå–æ—¶é—´
            self.credentials["extracted_at"] = datetime.now().isoformat()

            logger.debug(f"æ›´æ–°è®¤è¯å‡­è¯: CSRF={bool(csrf_token)}, Cookies={len(self.credentials['cookies'])}")

    def _parse_cookies(self, cookie_header: str) -> None:
        """è§£æCookieå­—ç¬¦ä¸²

        Args:
            cookie_header: Cookieå¤´å­—ç¬¦ä¸²
        """
        for cookie_pair in cookie_header.split(";"):
            if "=" in cookie_pair:
                name, value = cookie_pair.strip().split("=", 1)
                self.credentials["cookies"][name] = value

    def get_credentials(self) -> Dict:
        """è·å–å½“å‰çš„è®¤è¯å‡­è¯

        Returns:
            è®¤è¯å‡­è¯å­—å…¸
        """
        with self._lock:
            return self.credentials.copy()

    def is_valid(self) -> bool:
        """æ£€æŸ¥è®¤è¯å‡­è¯æ˜¯å¦æœ‰æ•ˆ

        Returns:
            å‡­è¯æ˜¯å¦æœ‰æ•ˆ
        """
        return bool(self.credentials["csrf_token"] and self.credentials["cookies"])


class NetworkInterceptor:
    """Pinterestç½‘ç»œè¯·æ±‚æ‹¦æˆªå™¨ - å¢å¼ºç‰ˆ

    æ”¯æŒæ•°æ®æå–ã€å‡­è¯ç®¡ç†å’ŒPinè¯¦æƒ…é¡µæ»šåŠ¨ç­–ç•¥
    """

    def __init__(self, output_dir: str = "network_analysis/results", max_cache_size: int = 1000, verbose: bool = True, target_count: int = 0, mode: str = "full"):
        """åˆå§‹åŒ–ç½‘ç»œæ‹¦æˆªå™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            max_cache_size: æœ€å¤§ç¼“å­˜å¤§å°ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
            target_count: ç›®æ ‡é‡‡é›†æ•°é‡ï¼Œç”¨äºè¿›åº¦æ¡æ˜¾ç¤º
            mode: æ‹¦æˆªæ¨¡å¼ ("full": å…¨éƒ¨API, "related_only": ä»…RelatedModulesResource)
        """
        self.verbose = verbose
        self.output_dir = output_dir
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.max_cache_size = max_cache_size
        self.target_count = target_count
        self.mode = mode

        # ä½¿ç”¨dequeå®ç°æ»‘åŠ¨çª—å£ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
        self.network_logs = deque(maxlen=max_cache_size)
        self.api_responses = deque(maxlen=max_cache_size)

        # æ–°å¢ï¼šæå–çš„Pinæ•°æ®å’Œè®¤è¯å‡­è¯
        self.extracted_pins = deque(maxlen=max_cache_size)
        self.pin_extractor = PinDataExtractor()
        self.credential_extractor = CredentialExtractor()

        # çº¿ç¨‹å®‰å…¨é”
        self._lock = threading.Lock()

        # èµ„æºæ¸…ç†è·Ÿè¸ª
        self._cleanup_handlers = []
        self._is_cleaned_up = False

        # è¿›åº¦æ¡ï¼ˆå¦‚æœè®¾ç½®äº†ç›®æ ‡æ•°é‡ï¼‰
        self.pbar = None
        if target_count > 0:
            self.pbar = tqdm(total=target_count, desc="APIé‡‡é›†", unit="pins", leave=False)

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_requests": 0,
            "total_responses": 0,
            "total_pins_extracted": 0,
            "api_endpoints_hit": set(),
            "session_start_time": time.time()
        }
        
        # åˆ›å»ºä¼šè¯ä¸“ç”¨ç›®å½•
        self.session_dir = os.path.join(output_dir, f"session_{self.session_id}")
        os.makedirs(self.session_dir, exist_ok=True)
        os.makedirs(os.path.join(self.session_dir, "network_logs"), exist_ok=True)
        os.makedirs(os.path.join(self.session_dir, "api_responses"), exist_ok=True)
        
        # æ ¹æ®æ¨¡å¼è®¾ç½®APIæ‹¦æˆªè§„åˆ™
        if self.mode == "related_only":
            # ç¬¬äºŒé˜¶æ®µï¼šåªå…³æ³¨GraphQLç«¯ç‚¹çš„v3RelatedPinsForPinSeoQuery
            self.pinterest_api_patterns = [
                "_/graphql/"
            ]
            if self.verbose:
                logger.info("ğŸ¯ NetworkInterceptoræ¨¡å¼: ä»…æ‹¦æˆªGraphQLç«¯ç‚¹")
        else:
            # ç¬¬ä¸€é˜¶æ®µï¼šå…¨éƒ¨APIæ¨¡å¼
            self.pinterest_api_patterns = [
                "api.pinterest.com",
                "v3/search/pins",
                "BoardFeedResource",
                "SearchResource",
                "BaseSearchResource",  # æœç´¢API
                "UserPinsResource",
                "RelatedPinsResource",  # Pinè¯¦æƒ…é¡µç›¸å…³æ¨è
                "RelatedModulesResource",  # ğŸ”¥ ä¿®å¤ï¼šæ·»åŠ å…³é”®çš„RelatedModulesResource
                "PinResource",
                "VisualSearchResource",  # è§†è§‰æœç´¢
                "HomefeedResource",  # é¦–é¡µæ¨è
                "resource/",
                "/v3/",
                "graphql",
                "_/graphql/",  # GraphQLç«¯ç‚¹
                "CloseupDetailsResource",  # Pinè¯¦æƒ…
                "MoreLikeThisResource",  # æ›´å¤šç›¸ä¼¼å†…å®¹
                "RelatedPinFeedResource"  # ç›¸å…³Pinæ¨è
            ]
            if self.verbose:
                logger.info("ğŸ” NetworkInterceptoræ¨¡å¼: æ‹¦æˆªæ‰€æœ‰Pinterest API")
        
        if self.verbose:
            logger.info(f"ç½‘ç»œæ‹¦æˆªå™¨åˆå§‹åŒ–å®Œæˆï¼Œä¼šè¯ID: {self.session_id}")
            logger.info(f"è¾“å‡ºç›®å½•: {self.session_dir}")
    
    def _is_pinterest_api_request(self, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºPinterest APIè¯·æ±‚

        Args:
            url: è¯·æ±‚URL

        Returns:
            æ˜¯å¦ä¸ºPinterest APIè¯·æ±‚
        """
        for pattern in self.pinterest_api_patterns:
            if pattern in url:
                if self.verbose:
                    logger.debug(f"âœ… åŒ¹é…Pinterest API: {url} (æ¨¡å¼: {pattern})")
                return True
        # ç§»é™¤æœªåŒ¹é…çš„DEBUGæ—¥å¿—ï¼Œå‡å°‘å†—ä½™è¾“å‡º
        return False
    
    def _extract_request_info(self, request: Request) -> Dict:
        """æå–è¯·æ±‚ä¿¡æ¯
        
        Args:
            request: Playwrightè¯·æ±‚å¯¹è±¡
            
        Returns:
            è¯·æ±‚ä¿¡æ¯å­—å…¸
        """
        parsed_url = urlparse(request.url)
        query_params = parse_qs(parsed_url.query)
        
        request_info = {
            "timestamp": datetime.now().isoformat(),
            "method": request.method,
            "url": request.url,
            "domain": parsed_url.netloc,
            "path": parsed_url.path,
            "query_params": query_params,
            "headers": dict(request.headers),
            "resource_type": request.resource_type,
            "post_data": request.post_data if request.method == "POST" else None
        }
        
        return request_info
    
    async def _extract_response_info(self, response: Response) -> Dict:
        """æå–å“åº”ä¿¡æ¯

        Args:
            response: Playwrightå“åº”å¯¹è±¡

        Returns:
            å“åº”ä¿¡æ¯å­—å…¸
        """
        response_info = {
            "timestamp": datetime.now().isoformat(),
            "status": response.status,
            "status_text": response.status_text,
            "url": response.url,
            "headers": dict(response.headers),
            "content_type": response.headers.get("content-type", ""),
            "size": 0  # é»˜è®¤ä¸º0ï¼Œç¨åå°è¯•è·å–
        }
        
        # å®‰å…¨åœ°è·å–å“åº”ä½“å¤§å°
        try:
            body = await response.body()
            response_info["size"] = len(body) if body else 0
        except Exception as e:
            logger.debug(f"æ— æ³•è·å–å“åº”ä½“å¤§å°: {e}")
            response_info["size"] = 0
        
        # å°è¯•æå–JSONæ•°æ®
        try:
            if "application/json" in response_info["content_type"]:
                json_data = await response.json()
                response_info["json_data"] = json_data
                
                # åˆ†æJSONç»“æ„ä¸­çš„å…³é”®ä¿¡æ¯
                if isinstance(json_data, dict):
                    # æŸ¥æ‰¾å¸¸è§çš„Pinterestæ•°æ®ç»“æ„
                    if "resource_response" in json_data:
                        response_info["has_resource_response"] = True
                        resource_data = json_data["resource_response"]
                        if "data" in resource_data:
                            response_info["data_keys"] = list(resource_data["data"].keys()) if isinstance(resource_data["data"], dict) else []
                    
                    # æŸ¥æ‰¾åˆ†é¡µä¿¡æ¯
                    if "bookmarks" in json_data:
                        response_info["has_bookmarks"] = True
                        response_info["bookmarks"] = json_data["bookmarks"]
                    
                    # æŸ¥æ‰¾pinsæ•°æ®
                    if "results" in json_data:
                        response_info["has_results"] = True
                        if isinstance(json_data["results"], list):
                            response_info["results_count"] = len(json_data["results"])
                
        except Exception as e:
            logger.debug(f"æ— æ³•è§£æJSONå“åº”: {e}")
            response_info["json_parse_error"] = str(e)
        
        return response_info
    
    def _handle_request(self, request: Request):
        """å¤„ç†è¯·æ±‚äº‹ä»¶ - å¢å¼ºç‰ˆï¼Œæ”¯æŒè®¤è¯ä¿¡æ¯æå–

        Args:
            request: Playwrightè¯·æ±‚å¯¹è±¡
        """
        try:
            if self._is_pinterest_api_request(request.url):
                request_info = self._extract_request_info(request)

                # æå–è®¤è¯å‡­è¯
                self.credential_extractor.extract_from_request(request_info)

                # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ åˆ°ç½‘ç»œæ—¥å¿—
                with self._lock:
                    log_entry = {
                        "type": "request",
                        "data": request_info,
                        "timestamp": time.time()
                    }
                    self.network_logs.append(log_entry)
                    self.stats["total_requests"] += 1

                    # è®°å½•APIç«¯ç‚¹
                    parsed_url = urlparse(request.url)
                    endpoint = parsed_url.path
                    self.stats["api_endpoints_hit"].add(endpoint)

                if self.verbose:
                    logger.debug(f"ğŸ” æ‹¦æˆªAPIè¯·æ±‚: {request.method} {request.url}")
                    logger.debug(f"ğŸ“Š å½“å‰æ—¥å¿—æ•°é‡: {len(self.network_logs)}, è®¤è¯å‡­è¯æœ‰æ•ˆ: {self.credential_extractor.is_valid()}")
        except Exception as e:
            logger.error(f"å¤„ç†è¯·æ±‚äº‹ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            logger.error(f"è¯·æ±‚URL: {request.url}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    async def _handle_response(self, response: Response):
        """å¤„ç†å“åº”äº‹ä»¶ - å¢å¼ºç‰ˆï¼Œæ”¯æŒPinæ•°æ®æå–

        Args:
            response: Playwrightå“åº”å¯¹è±¡
        """
        try:
            is_pinterest_api = self._is_pinterest_api_request(response.url)
            if self.verbose and is_pinterest_api:
                logger.debug(f"ğŸ“¥ å¤„ç†Pinterest APIå“åº”: {response.url}, çŠ¶æ€: {response.status}")
            if is_pinterest_api:
                response_info = await self._extract_response_info(response)

                # çº¿ç¨‹å®‰å…¨åœ°å¤„ç†å“åº”
                with self._lock:
                    # æŸ¥æ‰¾å…³è”è¯·æ±‚
                    related_request = next((log for log in reversed(self.network_logs)
                                            if log['type'] == 'request' and log['data']['url'] == response.request.url), None)

                    if related_request:
                        # å°†è¯·æ±‚å’Œå“åº”çš„å…³é”®ä¿¡æ¯æ•´åˆ
                        log_entry = {
                            "request_url": related_request['data']['url'],
                            "request_method": related_request['data']['method'],
                            "request_headers": related_request['data']['headers'],
                            "post_data": related_request['data'].get('post_data'),
                            "response_status": response_info['status'],
                            "response_headers": response_info['headers'],
                            "response_json": response_info.get('json_data'),
                            "timestamp": time.time()
                        }

                        # æ·»åŠ åˆ°æ—¥å¿—
                        self.network_logs.append({
                            "type": "response_paired",
                            "data": log_entry,
                            "timestamp": time.time()
                        })

                        # å¦‚æœæ˜¯æˆåŠŸçš„JSONå“åº”ï¼Œè¿›è¡Œæ•°æ®æå–
                        if response.status == 200 and "json_data" in response_info:
                            self.api_responses.append(log_entry)
                            self.stats["total_responses"] += 1

                            # æå–Pinæ•°æ®
                            json_data = response_info["json_data"]
                            extracted_pins = self.pin_extractor.extract_pins_from_response(json_data)

                            if extracted_pins:
                                # æ·»åŠ æå–çš„Pinæ•°æ®
                                for pin in extracted_pins:
                                    pin["source_api"] = response.url
                                    pin["extraction_timestamp"] = time.time()
                                    self.extracted_pins.append(pin)

                                self.stats["total_pins_extracted"] += len(extracted_pins)

                                # ä½¿ç”¨è¿›åº¦æ¡æ›¿ä»£é¢‘ç¹æ—¥å¿—
                                if self.pbar:
                                    self.pbar.update(len(extracted_pins))
                                    self.pbar.set_postfix({"æ€»è®¡": len(self.extracted_pins)})
                                elif self.verbose:
                                    # åªåœ¨æ²¡æœ‰è¿›åº¦æ¡æ—¶æ‰è¾“å‡ºæ—¥å¿—
                                    logger.debug(f"æå–åˆ° {len(extracted_pins)} ä¸ªPinï¼Œæ€»è®¡: {len(self.extracted_pins)}")
                            else:
                                # è°ƒè¯•ï¼šè®°å½•æœªæå–åˆ°Pinçš„æƒ…å†µ
                                if self.verbose and "_/graphql/" in response.url:
                                    logger.debug(f"GraphQLå“åº”æœªæå–åˆ°Pinæ•°æ®: {response.url}")
                                    if "data" in json_data:
                                        data_keys = list(json_data["data"].keys()) if isinstance(json_data["data"], dict) else []
                                        logger.debug(f"GraphQLå“åº”dataå­—æ®µåŒ…å«: {data_keys}")

                                        # è¯¦ç»†æ£€æŸ¥v3RelatedPinsForPinSeoQueryç»“æ„
                                        if "v3RelatedPinsForPinSeoQuery" in json_data["data"]:
                                            query_data = json_data["data"]["v3RelatedPinsForPinSeoQuery"]
                                            logger.debug(f"v3RelatedPinsForPinSeoQueryç»“æ„: {list(query_data.keys()) if isinstance(query_data, dict) else type(query_data)}")

                                            if isinstance(query_data, dict) and "data" in query_data:
                                                inner_data = query_data["data"]
                                                logger.debug(f"v3RelatedPinsForPinSeoQuery.dataç»“æ„: {list(inner_data.keys()) if isinstance(inner_data, dict) else type(inner_data)}")

                                                if isinstance(inner_data, dict) and "connection" in inner_data:
                                                    connection = inner_data["connection"]
                                                    logger.debug(f"connectionç»“æ„: {list(connection.keys()) if isinstance(connection, dict) else type(connection)}")

                                                    if isinstance(connection, dict) and "edges" in connection:
                                                        edges = connection["edges"]
                                                        logger.debug(f"edgesæ•°é‡: {len(edges) if isinstance(edges, list) else type(edges)}")

                                                        if isinstance(edges, list) and len(edges) > 0:
                                                            first_edge = edges[0]
                                                            logger.debug(f"ç¬¬ä¸€ä¸ªedgeç»“æ„: {list(first_edge.keys()) if isinstance(first_edge, dict) else type(first_edge)}")

                                                            if isinstance(first_edge, dict) and "node" in first_edge:
                                                                node = first_edge["node"]
                                                                logger.debug(f"ç¬¬ä¸€ä¸ªnodeç»“æ„: {list(node.keys())[:10] if isinstance(node, dict) else type(node)}")
                                                                logger.debug(f"nodeæœ‰entityId: {'entityId' in node if isinstance(node, dict) else False}")
                                                                logger.debug(f"nodeæœ‰imageSpec_orig: {'imageSpec_orig' in node if isinstance(node, dict) else False}")

                            if self.verbose:
                                logger.debug(f"ğŸ“Š APIå“åº”å¤„ç†å®Œæˆ: {response.url} (çŠ¶æ€: {response.status})")
                        else:
                            if self.verbose:
                                logger.debug(f"ğŸ“„ APIå“åº”: {response.url} (çŠ¶æ€: {response.status}), Content-Type: {response_info.get('content_type', 'N/A')}, Has JSON: {'json_data' in response_info}")
                    else:
                        # å¦‚æœæ‰¾ä¸åˆ°å…³è”è¯·æ±‚ï¼ŒæŒ‰åŸæ–¹å¼è®°å½•
                        self.network_logs.append({
                            "type": "response_unpaired",
                            "data": response_info,
                            "timestamp": time.time()
                        })
                        logger.warning(f"æœªæ‰¾åˆ°å…³è”è¯·æ±‚çš„å“åº”: {response.url}, çŠ¶æ€: {response_info['status']}")
        except Exception as e:
            logger.error(f"å¤„ç†å“åº”äº‹ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            logger.error(f"å“åº”URL: {response.url}")
            logger.error(f"å“åº”çŠ¶æ€: {response.status}")
            logger.error(f"å“åº”Content-Type: {response.headers.get('content-type', 'N/A')}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def get_request_by_filter(self, filter_func: Callable[[Dict], bool]) -> Optional[Dict]:
        """
        æ ¹æ®æŒ‡å®šçš„è¿‡æ»¤å‡½æ•°æŸ¥æ‰¾å¹¶è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„è¯·æ±‚æ—¥å¿—ã€‚

        Args:
            filter_func: ä¸€ä¸ªæ¥æ”¶è¯·æ±‚å­—å…¸å¹¶è¿”å›å¸ƒå°”å€¼çš„è¿‡æ»¤å‡½æ•°ã€‚

        Returns:
            ç¬¬ä¸€ä¸ªåŒ¹é…çš„è¯·æ±‚å­—å…¸ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› Noneã€‚
        """
        for log_entry in self.api_responses:
            # æˆ‘ä»¬åœ¨api_responsesä¸­å­˜å‚¨äº†æ•´åˆåçš„è¯·æ±‚/å“åº”å¯¹
            if filter_func(log_entry):
                # è¿”å›ä¸€ä¸ªæ›´é€‚åˆå‡­è¯æå–çš„ç»“æ„
                return {
                    "url": log_entry.get("request_url"),
                    "method": log_entry.get("request_method"),
                    "headers": log_entry.get("request_headers"),
                    "post_data": log_entry.get("post_data")
                }
        
        logger.warning("æœªé€šè¿‡è¿‡æ»¤å™¨æ‰¾åˆ°åŒ¹é…çš„è¯·æ±‚ã€‚")
        return None

    def get_extracted_pins(self) -> List[Dict]:
        """è·å–æå–çš„Pinæ•°æ®åˆ—è¡¨

        Returns:
            æå–çš„Pinæ•°æ®åˆ—è¡¨
        """
        with self._lock:
            return list(self.extracted_pins)

    def get_credentials(self) -> Dict:
        """è·å–æå–çš„è®¤è¯å‡­è¯

        Returns:
            è®¤è¯å‡­è¯å­—å…¸
        """
        return self.credential_extractor.get_credentials()

    def get_session_stats(self) -> Dict:
        """è·å–ä¼šè¯ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        with self._lock:
            current_time = time.time()
            session_duration = current_time - self.stats["session_start_time"]

            return {
                "session_id": self.session_id,
                "session_duration_seconds": session_duration,
                "total_requests": self.stats["total_requests"],
                "total_responses": self.stats["total_responses"],
                "total_pins_extracted": self.stats["total_pins_extracted"],
                "unique_api_endpoints": len(self.stats["api_endpoints_hit"]),
                "api_endpoints": list(self.stats["api_endpoints_hit"]),
                "credentials_valid": self.credential_extractor.is_valid(),
                "current_cache_sizes": {
                    "network_logs": len(self.network_logs),
                    "api_responses": len(self.api_responses),
                    "extracted_pins": len(self.extracted_pins)
                }
            }

    # ç§»é™¤äº†é‡å¤çš„æµè§ˆå™¨ç®¡ç†æ–¹æ³•ï¼Œç°åœ¨ä¸“æ³¨äºæ•°æ®æå–
    # æµè§ˆå™¨ç®¡ç†ç”±BrowserManagerç»Ÿä¸€å¤„ç†
    
    def _save_results(self):
        """ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶ - å¢å¼ºç‰ˆï¼Œæ”¯æŒPinæ•°æ®å’Œè®¤è¯å‡­è¯"""
        try:
            with self._lock:
                # ä¿å­˜ç½‘ç»œæ—¥å¿—
                network_log_file = os.path.join(self.session_dir, "network_logs", "requests.json")
                with open(network_log_file, 'w', encoding='utf-8') as f:
                    json.dump(list(self.network_logs), f, indent=2, ensure_ascii=False)

                # ä¿å­˜APIå“åº”
                api_response_file = os.path.join(self.session_dir, "api_responses", "responses.json")
                with open(api_response_file, 'w', encoding='utf-8') as f:
                    json.dump(list(self.api_responses), f, indent=2, ensure_ascii=False)

                # ä¿å­˜æå–çš„Pinæ•°æ®
                pins_data_file = os.path.join(self.session_dir, "extracted_pins.json")
                with open(pins_data_file, 'w', encoding='utf-8') as f:
                    json.dump(list(self.extracted_pins), f, indent=2, ensure_ascii=False)

                # ä¿å­˜è®¤è¯å‡­è¯
                credentials_file = os.path.join(self.session_dir, "credentials.json")
                with open(credentials_file, 'w', encoding='utf-8') as f:
                    json.dump(self.credential_extractor.get_credentials(), f, indent=2, ensure_ascii=False)

                # ä¿å­˜ä¼šè¯ç»Ÿè®¡
                stats_file = os.path.join(self.session_dir, "session_stats.json")
                with open(stats_file, 'w', encoding='utf-8') as f:
                    stats = self.get_session_stats()
                    # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
                    if "api_endpoints" in stats:
                        stats["api_endpoints"] = list(stats["api_endpoints"])
                    json.dump(stats, f, indent=2, ensure_ascii=False)

                logger.info(f"åˆ†æç»“æœå·²ä¿å­˜:")
                logger.info(f"  ç½‘ç»œæ—¥å¿—: {network_log_file}")
                logger.info(f"  APIå“åº”: {api_response_file}")
                logger.info(f"  æå–Pinæ•°æ®: {pins_data_file} ({len(self.extracted_pins)} ä¸ªPin)")
                logger.info(f"  è®¤è¯å‡­è¯: {credentials_file}")
                logger.info(f"  ä¼šè¯ç»Ÿè®¡: {stats_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†æç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def _generate_summary(self) -> Dict:
        """ç”Ÿæˆåˆ†ææ‘˜è¦ - å¢å¼ºç‰ˆï¼ŒåŒ…å«Pinæ•°æ®å’Œè®¤è¯ä¿¡æ¯

        Returns:
            åˆ†ææ‘˜è¦å­—å…¸
        """
        with self._lock:
            # ç»Ÿè®¡è¯·æ±‚ç±»å‹
            request_methods = {}
            api_endpoints = set()
            domains = set()

            for log in self.network_logs:
                if log["type"] == "request":
                    method = log["data"]["method"]
                    request_methods[method] = request_methods.get(method, 0) + 1

                    parsed_url = urlparse(log["data"]["url"])
                    domains.add(parsed_url.netloc)
                    api_endpoints.add(parsed_url.path)

            # ç»Ÿè®¡å“åº”çŠ¶æ€
            response_statuses = {}
            successful_responses = 0

            for response in self.api_responses:
                status = response.get("response_status", 0)
                response_statuses[status] = response_statuses.get(status, 0) + 1
                if status == 200:
                    successful_responses += 1

            # åˆ†ææå–çš„Pinæ•°æ®
            pin_stats = {
                "total_pins": len(self.extracted_pins),
                "pins_with_images": 0,
                "pins_with_stats": 0,
                "unique_creators": set(),
                "api_sources": set()
            }

            for pin in self.extracted_pins:
                if pin.get("image_urls"):
                    pin_stats["pins_with_images"] += 1
                if pin.get("stats"):
                    pin_stats["pins_with_stats"] += 1
                if pin.get("creator", {}).get("id"):
                    pin_stats["unique_creators"].add(pin["creator"]["id"])
                if pin.get("source_api"):
                    pin_stats["api_sources"].add(pin["source_api"])

            # è½¬æ¢setä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
            pin_stats["unique_creators"] = len(pin_stats["unique_creators"])
            pin_stats["api_sources"] = list(pin_stats["api_sources"])

            summary = {
                "session_id": self.session_id,
                "session_stats": self.get_session_stats(),
                "network_analysis": {
                    "total_requests": len([log for log in self.network_logs if log["type"] == "request"]),
                    "total_responses": len([log for log in self.network_logs if log["type"] in ["response_paired", "response_unpaired"]]),
                    "successful_api_responses": successful_responses,
                    "request_methods": request_methods,
                    "response_statuses": response_statuses,
                    "unique_domains": list(domains),
                    "unique_endpoints": list(api_endpoints)
                },
                "pin_extraction": pin_stats,
                "credentials": {
                    "is_valid": self.credential_extractor.is_valid(),
                    "has_csrf_token": bool(self.credential_extractor.credentials.get("csrf_token")),
                    "cookie_count": len(self.credential_extractor.credentials.get("cookies", {})),
                    "header_count": len(self.credential_extractor.credentials.get("headers", {}))
                },
                "output_directory": self.session_dir,
                "generated_at": datetime.now().isoformat()
            }

            return summary

    def export_for_http_api(self, output_file: Optional[str] = None) -> Dict:
        """å¯¼å‡ºæ•°æ®ç”¨äºåç»­HTTP APIè°ƒç”¨

        Args:
            output_file: å¯é€‰çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            åŒ…å«æ‰€æœ‰å¿…è¦æ•°æ®çš„å­—å…¸
        """
        with self._lock:
            # å‡†å¤‡HTTP APIè°ƒç”¨æ‰€éœ€çš„æ•°æ®
            export_data = {
                "session_info": {
                    "session_id": self.session_id,
                    "exported_at": datetime.now().isoformat(),
                    "total_pins_extracted": len(self.extracted_pins)
                },
                "credentials": self.credential_extractor.get_credentials(),
                "pins_data": list(self.extracted_pins),
                "api_patterns": {
                    "search_endpoints": [
                        "BaseSearchResource",
                        "SearchResource",
                        "VisualSearchResource"
                    ],
                    "pin_detail_endpoints": [
                        "RelatedPinsResource",
                        "CloseupDetailsResource",
                        "MoreLikeThisResource"
                    ],
                    "common_headers": self.credential_extractor.credentials.get("headers", {}),
                    "user_agent": self.credential_extractor.credentials.get("user_agent", "")
                },
                "sample_requests": self._get_sample_requests_for_http(),
                "usage_guide": {
                    "description": "æ­¤æ•°æ®å¯ç”¨äºæ„å»ºHTTP APIè¯·æ±‚ï¼Œç»•è¿‡æµè§ˆå™¨è‡ªåŠ¨åŒ–",
                    "steps": [
                        "1. ä½¿ç”¨credentialsä¸­çš„cookieså’Œheadersæ„å»ºHTTPè¯·æ±‚",
                        "2. å‚è€ƒsample_requestsä¸­çš„URLæ¨¡å¼å’Œå‚æ•°",
                        "3. ä½¿ç”¨pins_dataä¸­çš„Pin IDæ„å»ºè¯¦æƒ…é¡µè¯·æ±‚",
                        "4. å®ç°åˆ†é¡µæœºåˆ¶ä»¥è·å–æ›´å¤šæ•°æ®"
                    ],
                    "important_headers": [
                        "x-csrftoken",
                        "x-pinterest-appstate",
                        "x-requested-with",
                        "cookie",
                        "user-agent"
                    ]
                }
            }

            # å¦‚æœæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶ï¼Œä¿å­˜æ•°æ®
            if output_file:
                try:
                    output_path = os.path.join(self.session_dir, output_file)
                    with open(output_path, 'w', encoding='utf-8') as f:
                        json.dump(export_data, f, indent=2, ensure_ascii=False)
                    logger.info(f"HTTP APIæ•°æ®å·²å¯¼å‡ºåˆ°: {output_path}")
                except Exception as e:
                    logger.error(f"å¯¼å‡ºHTTP APIæ•°æ®å¤±è´¥: {e}")

            return export_data

    def _get_sample_requests_for_http(self) -> List[Dict]:
        """è·å–ç”¨äºHTTP APIçš„ç¤ºä¾‹è¯·æ±‚

        Returns:
            ç¤ºä¾‹è¯·æ±‚åˆ—è¡¨
        """
        sample_requests = []

        # ä»å·²æ•è·çš„APIå“åº”ä¸­æå–ç¤ºä¾‹
        for response in list(self.api_responses)[-5:]:  # å–æœ€è¿‘5ä¸ªå“åº”ä½œä¸ºç¤ºä¾‹
            if response.get("request_url") and response.get("request_method"):
                sample_request = {
                    "method": response["request_method"],
                    "url": response["request_url"],
                    "headers": response.get("request_headers", {}),
                    "post_data": response.get("post_data"),
                    "response_status": response.get("response_status"),
                    "api_type": self._classify_api_endpoint(response["request_url"])
                }
                sample_requests.append(sample_request)

        return sample_requests

    def _classify_api_endpoint(self, url: str) -> str:
        """åˆ†ç±»APIç«¯ç‚¹ç±»å‹

        Args:
            url: API URL

        Returns:
            APIç±»å‹
        """
        if "BaseSearchResource" in url or "SearchResource" in url:
            return "search"
        elif "RelatedPinsResource" in url or "MoreLikeThisResource" in url:
            return "related_pins"
        elif "CloseupDetailsResource" in url or "PinResource" in url:
            return "pin_detail"
        elif "graphql" in url:
            return "graphql"
        else:
            return "other"

    def clear_cache(self):
        """æ¸…ç†ç¼“å­˜æ•°æ®ï¼Œé‡Šæ”¾å†…å­˜

        å†³ç­–ç†ç”±ï¼šé•¿æ—¶é—´è¿è¡Œæ—¶é˜²æ­¢å†…å­˜æ³„æ¼
        """
        with self._lock:
            self.network_logs.clear()
            self.api_responses.clear()
            self.extracted_pins.clear()

            # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
            self.stats = {
                "total_requests": 0,
                "total_responses": 0,
                "total_pins_extracted": 0,
                "api_endpoints_hit": set(),
                "session_start_time": time.time()
            }

            logger.info("ç¼“å­˜å·²æ¸…ç†ï¼Œå†…å­˜å·²é‡Šæ”¾")

    def close_progress_bar(self):
        """å…³é—­è¿›åº¦æ¡"""
        if self.pbar:
            self.pbar.close()
            self.pbar = None

    async def cleanup(self):
        """æ¸…ç†èµ„æºï¼Œæ³¨é”€äº‹ä»¶å¤„ç†å™¨"""
        if self._is_cleaned_up:
            return

        try:
            # å…³é—­è¿›åº¦æ¡
            self.close_progress_bar()

            # æ¸…ç†ç¼“å­˜
            self.clear_cache()

            # æ‰§è¡Œæ‰€æœ‰æ¸…ç†å‡½æ•°
            for cleanup_func in self._cleanup_handlers:
                try:
                    if asyncio.iscoroutinefunction(cleanup_func):
                        await cleanup_func()
                    else:
                        cleanup_func()
                except Exception as e:
                    logger.debug(f"æ¸…ç†å¤„ç†å™¨æ—¶å‡ºé”™: {e}")

            self._cleanup_handlers.clear()
            self._is_cleaned_up = True
            logger.debug("NetworkInterceptorèµ„æºå·²æ¸…ç†")
        except Exception as e:
            logger.error(f"NetworkInterceptoræ¸…ç†å¤±è´¥: {e}")

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        await self.cleanup()

    def add_cleanup_handler(self, handler):
        """æ·»åŠ æ¸…ç†å¤„ç†å™¨"""
        if not self._is_cleaned_up:
            self._cleanup_handlers.append(handler)