#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å¼‚æ­¥æµè§ˆå™¨ç®¡ç†å™¨

æä¾›ç»Ÿä¸€çš„å¼‚æ­¥æµè§ˆå™¨ç®¡ç†æ¥å£ï¼Œæ”¯æŒæ•°æ®é‡‡é›†å’Œç½‘ç»œæ‹¦æˆªåŠŸèƒ½
"""

import json
import os
import time
import asyncio
from typing import Dict, List, Optional, Callable, Any

from loguru import logger
from patchright.async_api import async_playwright, Page, BrowserContext, Error
from tqdm import tqdm

from . import config


class BrowserManager:
    """å¼‚æ­¥æµè§ˆå™¨ç®¡ç†å™¨

    æä¾›ç»Ÿä¸€çš„å¼‚æ­¥æµè§ˆå™¨ç®¡ç†æ¥å£ï¼Œæ”¯æŒæ•°æ®é‡‡é›†ã€æ»šåŠ¨æ”¶é›†å’Œç½‘ç»œæ‹¦æˆªåŠŸèƒ½
    """

    def __init__(
        self,
        proxy: Optional[str] = None,
        timeout: int = config.DEFAULT_TIMEOUT,
        cookie_path: Optional[str] = None,
        headless: bool = True,
        enable_network_interception: bool = False,
        browser_type: str = 'chromium'
    ):
        """åˆå§‹åŒ–æµè§ˆå™¨ç®¡ç†å™¨

        Args:
            proxy: ä»£ç†æœåŠ¡å™¨åœ°å€
            timeout: é»˜è®¤è¶…æ—¶æ—¶é—´(ç§’)
            cookie_path: Cookieæ–‡ä»¶è·¯å¾„
            headless: æ˜¯å¦æ— å¤´æ¨¡å¼
            enable_network_interception: æ˜¯å¦å¯ç”¨ç½‘ç»œæ‹¦æˆª
            browser_type: æµè§ˆå™¨ç±»å‹ ('chromium', 'firefox', 'webkit')
        """
        self.proxy = proxy
        self.timeout = timeout or config.DEFAULT_TIMEOUT  # ä½¿ç”¨ä¼˜åŒ–çš„é»˜è®¤è¶…æ—¶
        self.cookie_path = cookie_path or config.COOKIE_FILE_PATH
        self.headless = headless
        self.enable_network_interception = enable_network_interception
        self.browser_type = browser_type
        
        # æµè§ˆå™¨å®ä¾‹
        self.playwright_instance = None
        self.browser = None
        self.browser_context = None
        self.page = None
        
        # ç½‘ç»œæ‹¦æˆªå›è°ƒ
        self.request_handlers = []
        self.response_handlers = []

        # äº‹ä»¶å¤„ç†å™¨è·Ÿè¸ª
        self._registered_handlers = []
        
        # ç”¨æˆ·ä»£ç† - ä½¿ç”¨æ›´å¯é çš„UA
        self.user_agent = self._get_reliable_user_agent()

    async def start(self) -> bool:
        """å¯åŠ¨æµè§ˆå™¨

        Returns:
            å¯åŠ¨æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.debug("å¯åŠ¨æµè§ˆå™¨ç®¡ç†å™¨...")

            # å¯åŠ¨Playwright
            self.playwright_instance = await async_playwright().start()
            
            # é…ç½®å¯åŠ¨é€‰é¡¹
            launch_options = {
                "headless": self.headless,
                "args": config.BROWSER_ARGS,
                "slow_mo": 100,  # æ·»åŠ 100mså»¶è¿Ÿï¼Œå‡å°‘æ£€æµ‹é£é™©
                "timeout": 60000,  # 60ç§’å¯åŠ¨è¶…æ—¶
            }

            # ä»£ç†é…ç½®
            if self.proxy:
                proxy_config = {"server": self.proxy}
                launch_options["proxy"] = proxy_config
                logger.info(f"ä½¿ç”¨ä»£ç†: {self.proxy}")
            
            # å¯åŠ¨æµè§ˆå™¨ - æ ¹æ®browser_typeé€‰æ‹©
            if self.browser_type == 'chromium':
                self.browser = await self.playwright_instance.chromium.launch(**launch_options)
            elif self.browser_type == 'firefox':
                self.browser = await self.playwright_instance.firefox.launch(**launch_options)
            elif self.browser_type == 'webkit':
                self.browser = await self.playwright_instance.webkit.launch(**launch_options)
            else:
                # é»˜è®¤ä½¿ç”¨chromium
                self.browser = await self.playwright_instance.chromium.launch(**launch_options)
                logger.warning(f"æœªçŸ¥çš„æµè§ˆå™¨ç±»å‹ {self.browser_type}ï¼Œä½¿ç”¨é»˜è®¤çš„chromium")

            # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡ - å¢å¼ºåçˆ¬è™«é…ç½®
            context_options = {
                "user_agent": self.user_agent,
                "viewport": {"width": 1920, "height": 1080},
                "java_script_enabled": True,
                "locale": "en-US",
                "timezone_id": "America/New_York",
                "permissions": ["geolocation"],
                "extra_http_headers": self._get_anti_detection_headers(),
            }
            
            # åŠ è½½Cookie
            if os.path.exists(self.cookie_path):
                try:
                    with open(self.cookie_path, 'r') as f:
                        storage_state = json.load(f)
                    context_options["storage_state"] = storage_state
                    logger.debug(f"æˆåŠŸåŠ è½½Cookie: {self.cookie_path}")
                except Exception as e:
                    logger.warning(f"åŠ è½½Cookieå¤±è´¥: {e}")
            
            self.browser_context = await self.browser.new_context(**context_options)
            self.page = await self.browser_context.new_page()
            
            # é˜»æ­¢ä¸å¿…è¦çš„èµ„æº
            if hasattr(config, "BLOCKED_RESOURCE_TYPES"):
                await self.page.route("**/*", lambda route: (
                    route.abort()
                    if route.request.resource_type in config.BLOCKED_RESOURCE_TYPES
                    else route.continue_()
                ))
            
            # è®¾ç½®è¶…æ—¶
            self.page.set_default_timeout(self.timeout * 1000)
            
            # è®¾ç½®ç½‘ç»œæ‹¦æˆª
            if self.enable_network_interception:
                self.page.on("request", self._handle_request)
                self.page.on("response", self._handle_response)
                self._registered_handlers.extend([
                    ("request", self._handle_request),
                    ("response", self._handle_response)
                ])
            
            logger.debug("æµè§ˆå™¨ç®¡ç†å™¨å¯åŠ¨æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
            return False

    async def stop(self):
        """å…³é—­æµè§ˆå™¨"""
        try:
            logger.debug("å¼€å§‹å…³é—­æµè§ˆå™¨...")

            # æ³¨é”€äº‹ä»¶å¤„ç†å™¨
            if self.page and self._registered_handlers:
                for event_type, handler in self._registered_handlers:
                    try:
                        self.page.off(event_type, handler)
                    except Exception as e:
                        logger.debug(f"æ³¨é”€{event_type}å¤„ç†å™¨å¤±è´¥: {e}")
                self._registered_handlers.clear()

            # æŒ‰é¡ºåºå…³é—­èµ„æº
            if self.page:
                try:
                    await self.page.close()
                    logger.debug("é¡µé¢å·²å…³é—­")
                except Exception as e:
                    logger.debug(f"å…³é—­é¡µé¢å¤±è´¥: {e}")

            if self.browser_context:
                try:
                    await self.browser_context.close()
                    logger.debug("æµè§ˆå™¨ä¸Šä¸‹æ–‡å·²å…³é—­")
                except Exception as e:
                    logger.debug(f"å…³é—­æµè§ˆå™¨ä¸Šä¸‹æ–‡å¤±è´¥: {e}")

            if self.browser:
                try:
                    await self.browser.close()
                    logger.debug("æµè§ˆå™¨å·²å…³é—­")
                except Exception as e:
                    logger.debug(f"å…³é—­æµè§ˆå™¨å¤±è´¥: {e}")

            if self.playwright_instance:
                try:
                    await self.playwright_instance.stop()
                    logger.debug("Playwrightå®ä¾‹å·²åœæ­¢")
                except Exception as e:
                    logger.debug(f"åœæ­¢Playwrightå®ä¾‹å¤±è´¥: {e}")

            logger.debug("æµè§ˆå™¨èµ„æºæ¸…ç†å®Œæˆ")

        except Exception as e:
            logger.error(f"å…³é—­æµè§ˆå™¨å‡ºé”™: {e}")
        finally:
            # ç¡®ä¿æ‰€æœ‰å¼•ç”¨éƒ½è¢«æ¸…ç†
            self.page = None
            self.browser_context = None
            self.browser = None
            self.playwright_instance = None
            self.request_handlers.clear()
            self.response_handlers.clear()

    async def navigate(self, url: str) -> bool:
        """å¯¼èˆªåˆ°æŒ‡å®šURL - é»˜è®¤ä¼˜åŒ–ç‰ˆæœ¬ï¼Œé›†æˆé‡è¯•å’Œå»¶è¿Ÿ

        Args:
            url: ç›®æ ‡URL

        Returns:
            å¯¼èˆªæ˜¯å¦æˆåŠŸ
        """
        # å›ºå®š3æ¬¡é‡è¯•ï¼Œé—´éš”é€’å¢ï¼š5s, 10s, 15s
        max_retries = 3
        retry_delays = [5, 10, 15]

        for attempt in range(max_retries):
            try:
                logger.info(f"å¯¼èˆªåˆ°: {url} (å°è¯• {attempt + 1}/{max_retries})")

                # å¦‚æœæ˜¯Pinterestæœç´¢URLï¼Œå…ˆå»ºç«‹ä¼šè¯
                if "pinterest.com/search" in url:
                    await self._establish_pinterest_session()

                # ä½¿ç”¨120ç§’è¶…æ—¶ï¼Œç­‰å¾…æ–‡æ¡£åŠ è½½å®Œæˆå³å¯ï¼ˆä¸éœ€è¦ç½‘ç»œç©ºé—²ï¼‰
                await self.page.goto(url, timeout=120000, wait_until="domcontentloaded")

                # å¯¼èˆªæˆåŠŸåçš„äººç±»è¡Œä¸ºå»¶è¿Ÿ
                await self._human_like_delay(2.0, 4.0)

                # æ£€æŸ¥é¡µé¢çŠ¶æ€
                current_url = self.page.url
                title = await self.page.title()

                # æ£€æµ‹é”™è¯¯é¡µé¢
                error_indicators = ["error", "blocked", "captcha", "robot", "denied"]
                if any(indicator in current_url.lower() or indicator in title.lower()
                       for indicator in error_indicators):
                    raise Error(f"æ£€æµ‹åˆ°é”™è¯¯é¡µé¢: {current_url} - {title}")

                logger.info(f"âœ… å¯¼èˆªæˆåŠŸ: {current_url}")
                return True

            except Exception as e:
                error_msg = str(e)
                logger.warning(f"å¯¼èˆªå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {error_msg}")

                # ç‰¹æ®Šå¤„ç†è¿æ¥å…³é—­é”™è¯¯
                if "ERR_CONNECTION_CLOSED" in error_msg or "net::ERR_CONNECTION_CLOSED" in error_msg:
                    logger.warning("æ£€æµ‹åˆ°è¿æ¥å…³é—­é”™è¯¯ï¼Œå¯èƒ½æ˜¯ç½‘ç»œä¸ç¨³å®šæˆ–Pintereståçˆ¬è™«æœºåˆ¶")

                    # å¯¹äºè¿æ¥å…³é—­é”™è¯¯ï¼Œå¢åŠ æ›´é•¿çš„ç­‰å¾…æ—¶é—´
                    if attempt < max_retries - 1:
                        wait_time = retry_delays[attempt] * 2  # åŒå€ç­‰å¾…æ—¶é—´
                        logger.info(f"è¿æ¥å…³é—­é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        await asyncio.sleep(wait_time)

                        # å°è¯•é‡æ–°å»ºç«‹æµè§ˆå™¨è¿æ¥
                        try:
                            await self.page.reload(timeout=30000)
                            await asyncio.sleep(3)
                        except:
                            logger.debug("é¡µé¢é‡è½½å¤±è´¥ï¼Œç»§ç»­é‡è¯•")
                    else:
                        logger.error(f"å¯¼èˆªæœ€ç»ˆå¤±è´¥ (è¿æ¥å…³é—­): {url}")
                        return False
                elif attempt < max_retries - 1:
                    # ä½¿ç”¨å›ºå®šçš„é‡è¯•å»¶è¿Ÿ
                    wait_time = retry_delays[attempt]
                    logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"å¯¼èˆªæœ€ç»ˆå¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {error_msg}")
                    return False

        return False

    async def scroll_and_collect(
        self,
        target_count: int,
        extract_func: Callable[[str], List[Dict]],
        max_scrolls: int = 100,
        scroll_pause: float = 2.0,
        no_new_data_limit: int = 10,
        initial_count: int = 0,
        repository=None,
        query: str = None,
        session_id: str = None
    ) -> List[Dict]:
        """æ™ºèƒ½æ»šåŠ¨å¹¶æ”¶é›†æ•°æ® - å®æ—¶ä¿å­˜ç‰ˆæœ¬

        Args:
            target_count: ç›®æ ‡æ•°æ®æ•°é‡
            extract_func: æ•°æ®æå–å‡½æ•°
            max_scrolls: æœ€å¤§æ»šåŠ¨æ¬¡æ•°
            scroll_pause: æ»šåŠ¨é—´éš”æ—¶é—´
            no_new_data_limit: è¿ç»­æ— æ–°æ•°æ®çš„é™åˆ¶æ¬¡æ•°
            initial_count: åˆå§‹å·²æœ‰æ•°æ®æ•°é‡ï¼ˆç”¨äºè¿›åº¦æ¡æ˜¾ç¤ºï¼‰
            repository: æ•°æ®åº“Repositoryå®ä¾‹ï¼Œç”¨äºå®æ—¶ä¿å­˜
            query: æœç´¢å…³é”®è¯
            session_id: ä¼šè¯ID

        Returns:
            ä»æ•°æ®åº“åŠ è½½çš„æ•°æ®åˆ—è¡¨ï¼ˆç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼‰
        """
        # å®æ—¶ä¿å­˜æ¨¡å¼æ£€æŸ¥
        realtime_save_enabled = repository is not None and query is not None
        if realtime_save_enabled:
            logger.info(f"ğŸ”„ å¯ç”¨å®æ—¶ä¿å­˜æ¨¡å¼ï¼Œç›®æ ‡: {target_count}")
        else:
            logger.warning("âš ï¸  æœªå¯ç”¨å®æ—¶ä¿å­˜æ¨¡å¼ï¼Œæ•°æ®å°†å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼ˆä¸æ¨èï¼‰")

        seen_ids = set()
        consecutive_no_new = 0
        scroll_count = 0
        saved_count = 0  # å®é™…ä¿å­˜åˆ°æ•°æ®åº“çš„æ•°é‡

        logger.info(f"å¼€å§‹æ•°æ®é‡‡é›†ï¼Œç›®æ ‡: {target_count}")

        # é¦–æ¬¡æå–é¡µé¢æ•°æ®ï¼ˆæ»šåŠ¨å‰ï¼‰
        html = await self.page.content()
        initial_items = extract_func(html)

        # å¤„ç†åˆå§‹æ•°æ®
        for item in initial_items:
            item_id = item.get('id')
            if item_id and item_id not in seen_ids:
                seen_ids.add(item_id)

                # å®æ—¶ä¿å­˜åˆ°æ•°æ®åº“
                if realtime_save_enabled:
                    try:
                        success = repository.save_pin_immediately(item, query, session_id)
                        if success:
                            saved_count += 1
                            logger.debug(f"ğŸ’¾ å®æ—¶ä¿å­˜Pin: {item_id} (æ€»è®¡: {saved_count})")
                        else:
                            logger.error(f"âŒ ä¿å­˜å¤±è´¥: {item_id}")
                    except Exception as e:
                        logger.error(f"âŒ ä¿å­˜å¼‚å¸¸: {item_id}, é”™è¯¯: {e}")

                if saved_count >= target_count:
                    break

        # åˆ›å»ºè¿›åº¦æ¡ï¼ŒåŸºäºå®é™…ä¿å­˜çš„æ•°æ®é‡
        current_progress = initial_count + saved_count
        pbar = tqdm(total=target_count + initial_count, desc="å®æ—¶ä¿å­˜", unit="pins",
                   initial=current_progress, leave=False)

        # é€€å‡ºæ¡ä»¶ï¼šè¾¾åˆ°ç›®æ ‡æ•°é‡ OR è¾¾åˆ°æœ€å¤§æ»šåŠ¨æ¬¡æ•° OR è¿ç»­æ— æ–°æ•°æ®
        while (saved_count < target_count and
               scroll_count < max_scrolls and
               consecutive_no_new < no_new_data_limit):

            # ä½¿ç”¨çœŸå®çš„PageDowné”®ç›˜äº‹ä»¶æ»šåŠ¨ï¼ˆæ¯”JavaScriptæ›´è‡ªç„¶ï¼‰
            scroll_count += 1
            await self.page.keyboard.press("PageDown")
            time.sleep(scroll_pause)

            # ç­‰å¾…é¡µé¢åŠ è½½ï¼ˆä½¿ç”¨domcontentloadedè€Œä¸æ˜¯networkidleï¼‰
            try:
                await self.page.wait_for_load_state('domcontentloaded', timeout=5000)
            except:
                # å¦‚æœç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ
                pass

            # æå–å½“å‰é¡µé¢æ•°æ®
            html = await self.page.content()
            new_items = extract_func(html)

            # å®æ—¶ä¿å­˜æ–°æ•°æ®
            items_before = saved_count
            for item in new_items:
                item_id = item.get('id')
                if item_id and item_id not in seen_ids:
                    seen_ids.add(item_id)

                    # å®æ—¶ä¿å­˜åˆ°æ•°æ®åº“
                    if realtime_save_enabled:
                        try:
                            success = repository.save_pin_immediately(item, query, session_id)
                            if success:
                                saved_count += 1
                                logger.debug(f"ğŸ’¾ å®æ—¶ä¿å­˜Pin: {item_id} (æ€»è®¡: {saved_count})")
                                # ç«‹å³æ›´æ–°è¿›åº¦æ¡
                                pbar.update(1)
                            else:
                                logger.error(f"âŒ ä¿å­˜å¤±è´¥: {item_id}")
                        except Exception as e:
                            logger.error(f"âŒ ä¿å­˜å¼‚å¸¸: {item_id}, é”™è¯¯: {e}")
                    else:
                        # é™çº§åˆ°å†…å­˜å­˜å‚¨ï¼ˆä¸æ¨èï¼‰
                        logger.warning(f"âš ï¸  é™çº§åˆ°å†…å­˜å­˜å‚¨: {item_id}")

                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
                    if saved_count >= target_count:
                        break

            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ•°æ®
            items_after = saved_count
            if items_after > items_before:
                consecutive_no_new = 0
            else:
                consecutive_no_new += 1

            # æ›´æ–°è¿›åº¦æ¡æè¿°
            pbar.set_postfix({
                'æ»šåŠ¨': scroll_count,
                'è¿ç»­æ— æ–°': consecutive_no_new,
                'å·²ä¿å­˜': saved_count
            })

            # ç¡¬æ€§ç›®æ ‡æ£€æŸ¥ï¼šè¾¾åˆ°ç›®æ ‡æ•°é‡ç«‹å³é€€å‡º
            if saved_count >= target_count:
                logger.info(f"âœ… å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {target_count}ï¼Œç«‹å³é€€å‡º")
                break

        # å…³é—­è¿›åº¦æ¡
        pbar.close()

        # è®°å½•åœæ­¢åŸå› 
        if saved_count >= target_count:
            stop_reason = "è¾¾åˆ°ç›®æ ‡æ•°é‡"
        elif scroll_count >= max_scrolls:
            stop_reason = f"è¾¾åˆ°æœ€å¤§æ»šåŠ¨æ¬¡æ•°"
        elif consecutive_no_new >= no_new_data_limit:
            stop_reason = f"è¿ç»­æ— æ–°æ•°æ®"
        else:
            stop_reason = "æœªçŸ¥åŸå› "

        # ä»æ•°æ®åº“åŠ è½½æœ€ç»ˆç»“æœï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
        if realtime_save_enabled:
            try:
                final_pins = repository.load_pins_by_query(query, limit=target_count)
                logger.info(f"âœ… å®æ—¶ä¿å­˜å®Œæˆ: {len(final_pins)}/{target_count} ({stop_reason})")
                return final_pins
            except Exception as e:
                logger.error(f"âŒ ä»æ•°æ®åº“åŠ è½½æ•°æ®å¤±è´¥: {e}")
                return []
        else:
            logger.warning(f"âš ï¸  æœªå¯ç”¨å®æ—¶ä¿å­˜ï¼Œè¿”å›ç©ºåˆ—è¡¨ ({stop_reason})")
            return []

    def add_request_handler(self, handler: Callable):
        """æ·»åŠ è¯·æ±‚å¤„ç†å™¨"""
        self.request_handlers.append(handler)

    def add_response_handler(self, handler: Callable):
        """æ·»åŠ å“åº”å¤„ç†å™¨"""
        self.response_handlers.append(handler)

    def _handle_request(self, request):
        """å¤„ç†è¯·æ±‚äº‹ä»¶"""
        for handler in self.request_handlers:
            try:
                handler(request)
            except Exception as e:
                logger.error(f"è¯·æ±‚å¤„ç†å™¨å‡ºé”™: {e}")

    def _handle_response(self, response):
        """å¤„ç†å“åº”äº‹ä»¶"""
        for handler in self.response_handlers:
            try:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¼‚æ­¥å¤„ç†å™¨
                if asyncio.iscoroutinefunction(handler):
                    # åˆ›å»ºä»»åŠ¡æ¥å¤„ç†å¼‚æ­¥å¤„ç†å™¨
                    asyncio.create_task(handler(response))
                else:
                    handler(response)
            except Exception as e:
                logger.error(f"å“åº”å¤„ç†å™¨å‡ºé”™: {e}")

    async def wait_for_load_state(self, state: str = "domcontentloaded", timeout: int = 30000):
        """ç­‰å¾…é¡µé¢åŠ è½½çŠ¶æ€"""
        try:
            await self.page.wait_for_load_state(state, timeout=timeout)
        except Exception as e:
            logger.debug(f"ç­‰å¾…åŠ è½½çŠ¶æ€è¶…æ—¶: {e}")

    async def get_html(self) -> str:
        """è·å–å½“å‰é¡µé¢HTML"""
        return await self.page.content()

    def is_ready(self) -> bool:
        """æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦å°±ç»ª"""
        return self.page is not None

    def _get_reliable_user_agent(self) -> str:
        """è·å–å¯é çš„User-Agent - é»˜è®¤ä¼˜åŒ–è¡Œä¸º"""
        # ç²¾é€‰çš„çœŸå®æµè§ˆå™¨User-Agentæ± ï¼Œç»è¿‡éªŒè¯çš„é«˜æˆåŠŸç‡UA
        RELIABLE_USER_AGENTS = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0"
        ]
        import random
        return random.choice(RELIABLE_USER_AGENTS)

    def _get_anti_detection_headers(self) -> Dict:
        """è·å–åæ£€æµ‹Headers - é»˜è®¤ä¼˜åŒ–é…ç½®"""
        # å®Œæ•´çš„åæ£€æµ‹Headersï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ç¯å¢ƒ
        return {
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
            "Accept-Language": "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
            "Accept-Encoding": "gzip, deflate, br, zstd",
            "Cache-Control": "max-age=0",
            "Sec-Ch-Ua": '"Chromium";v="138", "Not=A?Brand";v="8", "Google Chrome";v="138"',
            "Sec-Ch-Ua-Mobile": "?0",
            "Sec-Ch-Ua-Platform": '"Windows"',
            "Sec-Ch-Ua-Platform-Version": '"15.0.0"',
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Upgrade-Insecure-Requests": "1",
            "Connection": "keep-alive",
            "DNT": "1",
            "Sec-GPC": "1"
        }

    async def _human_like_delay(self, min_delay: float = 2.0, max_delay: float = 5.0):
        """äººç±»è¡Œä¸ºå»¶è¿Ÿ - é»˜è®¤ä¼˜åŒ–è¡Œä¸º"""
        import random
        # ä½¿ç”¨æ­£æ€åˆ†å¸ƒæ¨¡æ‹Ÿæ›´çœŸå®çš„äººç±»è¡Œä¸ºå»¶è¿Ÿ
        delay = random.uniform(min_delay, max_delay)
        logger.debug(f"äººç±»è¡Œä¸ºå»¶è¿Ÿ: {delay:.2f}ç§’")
        await asyncio.sleep(delay)

    async def _establish_pinterest_session(self):
        """å»ºç«‹Pinterestä¼šè¯ - é›†æˆå»¶è¿Ÿä¼˜åŒ–"""
        try:
            logger.debug("å»ºç«‹Pinterestä¼šè¯...")

            # å…ˆè®¿é—®ä¸»é¡µï¼ˆä½¿ç”¨120ç§’è¶…æ—¶ï¼‰
            await self.page.goto("https://www.pinterest.com/", timeout=120000, wait_until="domcontentloaded")
            await self._human_like_delay(2.0, 4.0)  # é»˜è®¤å»¶è¿Ÿ

            # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
            await self.page.evaluate("window.scrollBy(0, 500)")
            await self._human_like_delay(1.0, 2.0)  # æ»šåŠ¨åå»¶è¿Ÿ

            logger.debug("Pinterestä¼šè¯å»ºç«‹å®Œæˆ")

        except Exception as e:
            logger.warning(f"å»ºç«‹Pinterestä¼šè¯å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­æ‰§è¡Œ
