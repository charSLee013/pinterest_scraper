#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½é‡‡é›†å¼•æ“ - æ¿€è¿›é‡æ„ç‰ˆ

ç»Ÿä¸€çš„Pinterestæ•°æ®é‡‡é›†å¼•æ“ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥
"""

import time
import asyncio
from typing import Dict, List, Optional, Set
from collections import deque

from loguru import logger
from tqdm import tqdm

from .browser_manager import BrowserManager
from .parser import extract_pins_from_html
from ..utils.network_interceptor import NetworkInterceptor, PinDataExtractor
from . import config


class SmartScraper:
    """æ™ºèƒ½Pinteresté‡‡é›†å¼•æ“

    ç»Ÿä¸€ä½¿ç”¨hybridæ··åˆé‡‡é›†ç­–ç•¥ï¼Œé€‚ç”¨äºæ‰€æœ‰æ•°æ®é‡çº§

    ç­–ç•¥ç‰¹ç‚¹ï¼š
    - ç»Ÿä¸€ç­–ç•¥ï¼šæ‰€æœ‰æ•°æ®é‡çº§éƒ½ä½¿ç”¨hybridç­–ç•¥
    - æ™ºèƒ½è°ƒæ•´ï¼šæ ¹æ®ç›®æ ‡æ•°é‡åŠ¨æ€è°ƒæ•´é‡‡é›†å‚æ•°
    - å¤šé˜¶æ®µé‡‡é›†ï¼šå…³é”®è¯æœç´¢ + Pinè¯¦æƒ…é¡µæ·±åº¦æ‰©å±•
    """

    def __init__(
        self,
        proxy: Optional[str] = None,
        timeout: int = config.DEFAULT_TIMEOUT,
        cookie_path: Optional[str] = None,
        debug: bool = False,
        repository=None,
        session_id: Optional[str] = None
    ):
        """åˆå§‹åŒ–æ™ºèƒ½é‡‡é›†å¼•æ“

        Args:
            proxy: ä»£ç†æœåŠ¡å™¨åœ°å€
            timeout: è¶…æ—¶æ—¶é—´
            cookie_path: Cookieæ–‡ä»¶è·¯å¾„
            debug: è°ƒè¯•æ¨¡å¼
            repository: Repositoryå®ä¾‹ï¼Œç”¨äºå®æ—¶ä¿å­˜
            session_id: ä¼šè¯IDï¼Œç”¨äºä¼šè¯è¿½è¸ª
        """
        self.proxy = proxy
        self.timeout = timeout
        self.cookie_path = cookie_path
        self.debug = debug

        # å®æ—¶ä¿å­˜ç›¸å…³
        self.repository = repository
        self.session_id = session_id
        self._interrupt_requested = False
        self._saved_count = 0  # å·²ä¿å­˜çš„Pinæ•°é‡

        # æ•°æ®æ”¶é›†çŠ¶æ€
        self.collected_pins = []
        self.seen_pin_ids = set()

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_scrolls": 0,
            "api_calls_intercepted": 0,
            "html_extractions": 0,
            "duplicates_filtered": 0,
            "pins_saved_realtime": 0  # å®æ—¶ä¿å­˜çš„Pinæ•°é‡
        }

    async def scrape(
        self,
        query: Optional[str] = None,
        url: Optional[str] = None,
        target_count: int = 50,
        repository=None,
        session_id: Optional[str] = None
    ) -> List[Dict]:
        """æ™ºèƒ½é‡‡é›†Pinterestæ•°æ® - å®æ—¶å»é‡ç‰ˆ

        é‡‡ç”¨"å®æ—¶å»é‡å¹¶æŒç»­é‡‡é›†ç›´åˆ°è¾¾åˆ°ç›®æ ‡æ•°é‡"çš„ç­–ç•¥ï¼Œç¡®ä¿æœ€ç»ˆè¿”å›
        ç”¨æˆ·æŒ‡å®šæ•°é‡çš„å»é‡åå”¯ä¸€Pinã€‚

        Args:
            query: æœç´¢å…³é”®è¯
            url: ç›´æ¥URL
            target_count: ç›®æ ‡å»é‡åå”¯ä¸€Pinæ•°é‡
            repository: Repositoryå®ä¾‹ï¼Œç”¨äºå®æ—¶ä¿å­˜ï¼ˆä¼˜å…ˆçº§é«˜äºæ„é€ å‡½æ•°å‚æ•°ï¼‰
            session_id: ä¼šè¯IDï¼Œç”¨äºä¼šè¯è¿½è¸ªï¼ˆä¼˜å…ˆçº§é«˜äºæ„é€ å‡½æ•°å‚æ•°ï¼‰

        Returns:
            é‡‡é›†åˆ°çš„å»é‡åPinæ•°æ®åˆ—è¡¨
        """
        # æ›´æ–°å®æ—¶ä¿å­˜å‚æ•°ï¼ˆæ–¹æ³•å‚æ•°ä¼˜å…ˆçº§é«˜äºæ„é€ å‡½æ•°å‚æ•°ï¼‰
        if repository is not None:
            self.repository = repository
        if session_id is not None:
            self.session_id = session_id

        logger.info(f"å¼€å§‹æ™ºèƒ½é‡‡é›†ï¼Œç›®æ ‡: {target_count} ä¸ªå»é‡åå”¯ä¸€Pin")
        if self.repository:
            logger.info("å¯ç”¨å®æ—¶ä¿å­˜æ¨¡å¼")

        # è®°å½•é‡‡é›†å¼€å§‹æ—¶çš„åŸºå‡†æ•°é‡ï¼ˆåœ¨é‡ç½®çŠ¶æ€ä¹‹å‰ï¼‰
        self._baseline_count = self._get_saved_count_from_db(query) if self.repository else 0
        logger.debug(f"ğŸ“Š é‡‡é›†åŸºå‡†: æ•°æ®åº“ä¸­å·²æœ‰ {self._baseline_count} ä¸ªPin")

        # é‡ç½®çŠ¶æ€ï¼ˆä½†ä¿ç•™åŸºå‡†æ•°é‡ä¿¡æ¯ï¼‰
        self._reset_state()

        # æ¢å¤åŸºå‡†æ•°é‡ï¼ˆå› ä¸º_reset_stateä¼šé‡ç½®å®ƒï¼‰
        self._baseline_count = self._get_saved_count_from_db(query) if self.repository else 0

        # æ„å»ºç›®æ ‡URL
        target_url = self._build_url(query, url)
        if not target_url:
            logger.error("æ— æ•ˆçš„æŸ¥è¯¢å‚æ•°")
            return []

        # ç»Ÿä¸€ä½¿ç”¨hybridæ··åˆç­–ç•¥
        logger.info("ä½¿ç”¨ç»Ÿä¸€çš„hybridæ··åˆç­–ç•¥")

        try:
            # å®æ—¶å»é‡é‡‡é›†ä¸»å¾ªç¯
            return await self._adaptive_scrape_with_dedup(query, target_url, target_count)
        except KeyboardInterrupt:
            logger.warning("æ£€æµ‹åˆ°ç”¨æˆ·ä¸­æ–­ï¼Œä¿å­˜å·²é‡‡é›†æ•°æ®...")
            await self._handle_interrupt(query)
            raise

    async def _adaptive_scrape_with_dedup(
        self,
        query: Optional[str],
        target_url: str,
        target_count: int
    ) -> List[Dict]:
        """è‡ªé€‚åº”é‡‡é›†ï¼ŒåŸºäºæ•°æ®åº“çš„å®æ—¶å»é‡ç›´åˆ°è¾¾åˆ°ç›®æ ‡æ•°é‡

        Args:
            query: æœç´¢å…³é”®è¯
            target_url: ç›®æ ‡URL
            target_count: ç›®æ ‡å»é‡åæ•°é‡

        Returns:
            å»é‡åçš„Pinæ•°æ®åˆ—è¡¨ï¼ˆä»æ•°æ®åº“åŠ è½½ï¼‰
        """
        attempted_strategies = []
        max_rounds = 5  # æœ€å¤§é‡‡é›†è½®æ¬¡

        logger.info(f"å¼€å§‹åŸºäºæ•°æ®åº“çš„è‡ªé€‚åº”é‡‡é›†ï¼Œæœ€å¤§è½®æ¬¡: {max_rounds}")

        for round_num in range(max_rounds):
            # æ£€æŸ¥ä¸­æ–­è¯·æ±‚
            if self._interrupt_requested:
                logger.info("æ£€æµ‹åˆ°ä¸­æ–­è¯·æ±‚ï¼Œåœæ­¢é‡‡é›†")
                break

            # ä»æ•°æ®åº“è·å–å½“å‰å·²ä¿å­˜çš„Pinæ•°é‡
            current_total_count = self._get_saved_count_from_db(query)
            current_new_count = current_total_count - self._baseline_count  # æœ¬æ¬¡é‡‡é›†æ–°å¢çš„æ•°é‡
            remaining_needed = target_count - current_new_count

            logger.debug(f"ğŸ”¢ é‡‡é›†çŠ¶æ€: æ€»æ•°={current_total_count}, åŸºå‡†={self._baseline_count}, æ–°å¢={current_new_count}, ç›®æ ‡={target_count}, è¿˜éœ€={remaining_needed}")

            if remaining_needed <= 0:
                logger.info(f"å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {target_count}ï¼Œé‡‡é›†å®Œæˆ")
                break

            logger.info(f"ç¬¬ {round_num + 1} è½®é‡‡é›†ï¼Œæ€»æ•°: {current_total_count}ï¼Œæ–°å¢: {current_new_count}ï¼Œè¿˜éœ€: {remaining_needed}")

            # ç®€åŒ–é€»è¾‘ï¼šç›´æ¥ä½¿ç”¨å‰©ä½™éœ€è¦çš„æ•°é‡
            current_target = remaining_needed

            logger.info(f"æœ¬è½®ç›®æ ‡: {current_target} ä¸ªå»é‡åå”¯ä¸€Pin")

            # æ‰§è¡Œhybridæ··åˆç­–ç•¥
            logger.info(f"æ‰§è¡Œhybridç­–ç•¥ï¼Œç›®æ ‡: {current_target}")
            new_pins = await self._hybrid_scrape(query, current_target)
            attempted_strategies.append("hybrid")

            if not new_pins:
                logger.warning("hybridç­–ç•¥æœªè·å–åˆ°æ•°æ®")
                continue

            # å®æ—¶ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå»é‡åœ¨æ•°æ®åº“å±‚é¢å¤„ç†ï¼‰
            new_unique_count = await self._save_pins_to_db(new_pins, query)

            logger.info(f"æœ¬è½®æ–°å¢å”¯ä¸€Pin: {new_unique_count}")

            # æ£€æŸ¥å»é‡ç‡ï¼Œå¦‚æœè¿‡é«˜åˆ™åœæ­¢
            if round_num > 0 and new_unique_count == 0:
                logger.warning("æœ¬è½®æœªè·å¾—æ–°çš„å”¯ä¸€Pinï¼Œå¯èƒ½æ•°æ®æºå·²æ¯ç«­")
                break

            # é‡æ–°æ£€æŸ¥æ•°æ®åº“ä¸­çš„æ–°å¢æ•°é‡
            current_total_count = self._get_saved_count_from_db(query)
            current_new_count = current_total_count - self._baseline_count
            if current_new_count >= target_count:
                logger.info(f"å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œæå‰ç»“æŸé‡‡é›†")
                break

        # ä»æ•°æ®åº“åŠ è½½æœ€ç»ˆç»“æœï¼ˆåªè¿”å›æœ¬æ¬¡é‡‡é›†çš„ç›®æ ‡æ•°é‡ï¼‰
        all_pins = self._load_pins_from_db(query, None)  # åŠ è½½æ‰€æœ‰Pin
        final_pins = all_pins[-target_count:] if len(all_pins) >= target_count else all_pins  # å–æœ€æ–°çš„target_countä¸ª
        final_count = len(final_pins)

        logger.info(f"é‡‡é›†å®Œæˆ: {final_count}/{target_count} ä¸ªå”¯ä¸€Pin (ä½¿ç”¨ç­–ç•¥: {', '.join(set(attempted_strategies))})")

        return final_pins

    def _estimate_dedup_rate(self, collected_pins: List[Dict], round_num: int) -> float:
        """ä¼°ç®—å»é‡ç‡ï¼Œç”¨äºè°ƒæ•´é‡‡é›†ç›®æ ‡

        Args:
            collected_pins: å·²æ”¶é›†çš„Pinæ•°æ®
            round_num: å½“å‰è½®æ¬¡

        Returns:
            é¢„ä¼°å»é‡ç‡ï¼ˆ0-100ï¼‰
        """
        if round_num == 0 or len(collected_pins) < 10:
            # é¦–è½®æˆ–æ•°æ®å¤ªå°‘æ—¶ï¼Œä½¿ç”¨ä¿å®ˆä¼°è®¡
            return 20.0  # å‡è®¾20%çš„å»é‡ç‡

        # åŸºäºå·²æœ‰æ•°æ®ä¼°ç®—å»é‡ç‡
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯ä»¥æ ¹æ®æ•°æ®æºç‰¹å¾è¿›è¡Œæ›´ç²¾ç¡®çš„ä¼°ç®—
        if len(collected_pins) < 100:
            return 25.0
        elif len(collected_pins) < 500:
            return 30.0
        else:
            return 35.0  # æ•°æ®é‡å¤§æ—¶å»é‡ç‡é€šå¸¸æ›´é«˜

    def _calculate_adjusted_target(self, remaining_needed: int, estimated_dedup_rate: float) -> int:
        """æ ¹æ®é¢„ä¼°å»é‡ç‡è®¡ç®—è°ƒæ•´åçš„é‡‡é›†ç›®æ ‡

        Args:
            remaining_needed: è¿˜éœ€è¦çš„å”¯ä¸€Pinæ•°é‡
            estimated_dedup_rate: é¢„ä¼°å»é‡ç‡

        Returns:
            è°ƒæ•´åçš„é‡‡é›†ç›®æ ‡
        """
        # æ ¹æ®å»é‡ç‡è°ƒæ•´ç›®æ ‡ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„åŸå§‹æ•°æ®
        multiplier = 1.0 / (1.0 - estimated_dedup_rate / 100.0)
        adjusted_target = int(remaining_needed * multiplier * 1.2)  # é¢å¤–20%ç¼“å†²

        # è®¾ç½®åˆç†çš„ä¸Šä¸‹é™
        min_target = remaining_needed
        max_target = remaining_needed * 5  # æœ€å¤š5å€

        return max(min_target, min(adjusted_target, max_target))





    async def _save_pins_to_db(self, pins: List[Dict], query: Optional[str]) -> int:
        """å°†Pinæ•°æ®ä¿å­˜åˆ°æ•°æ®åº“ï¼Œè¿”å›æ–°å¢çš„å”¯ä¸€Pinæ•°é‡

        Args:
            pins: è¦ä¿å­˜çš„Pinæ•°æ®åˆ—è¡¨
            query: æœç´¢å…³é”®è¯

        Returns:
            æ–°å¢çš„å”¯ä¸€Pinæ•°é‡
        """
        if not self.repository or not query:
            logger.warning("æ— Repositoryæˆ–queryï¼Œæ— æ³•ä¿å­˜Pinæ•°æ®")
            return 0

        new_unique_count = 0

        for pin in pins:
            pin_id = pin.get('id')
            if not pin_id:
                continue

            try:
                # æ£€æŸ¥Pinæ˜¯å¦å·²å­˜åœ¨
                if not self._is_pin_exists_in_db(pin_id, query):
                    # ç›´æ¥ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä¸ä½¿ç”¨ç¼“å†²åŒºï¼‰
                    success = self.repository.save_pins_batch([pin], query, self.session_id)
                    if success:
                        new_unique_count += 1
                        self._saved_count += 1
                        self.stats["pins_saved_realtime"] += 1
                        logger.debug(f"ä¿å­˜æ–°Pinåˆ°æ•°æ®åº“: {pin_id} (æ€»è®¡: {self._saved_count})")
                    else:
                        logger.error(f"ä¿å­˜Pinåˆ°æ•°æ®åº“å¤±è´¥: {pin_id}")
                else:
                    logger.debug(f"Pinå·²å­˜åœ¨ï¼Œè·³è¿‡: {pin_id}")

            except Exception as e:
                logger.error(f"ä¿å­˜Pinæ—¶å‡ºé”™: {pin_id}, é”™è¯¯: {e}")

            # æ£€æŸ¥ä¸­æ–­è¯·æ±‚
            if self._interrupt_requested:
                logger.info(f"æ£€æµ‹åˆ°ä¸­æ–­è¯·æ±‚ï¼Œåœæ­¢ä¿å­˜Pin")
                break

        return new_unique_count

    def _get_saved_count_from_db(self, query: Optional[str]) -> int:
        """ä»æ•°æ®åº“è·å–å·²ä¿å­˜çš„Pinæ•°é‡"""
        if not self.repository or not query:
            return 0

        try:
            pins = self.repository.load_pins_by_query(query, limit=None)
            return len(pins)
        except Exception as e:
            logger.error(f"ä»æ•°æ®åº“è·å–Pinæ•°é‡å¤±è´¥: {e}")
            return 0

    def _load_pins_from_db(self, query: Optional[str], limit: int) -> List[Dict]:
        """ä»æ•°æ®åº“åŠ è½½Pinæ•°æ®"""
        if not self.repository or not query:
            return []

        try:
            return self.repository.load_pins_by_query(query, limit=limit)
        except Exception as e:
            logger.error(f"ä»æ•°æ®åº“åŠ è½½Pinæ•°æ®å¤±è´¥: {e}")
            return []

    def _is_pin_exists_in_db(self, pin_id: str, query: str) -> bool:
        """æ£€æŸ¥Pinæ˜¯å¦å·²å­˜åœ¨äºæ•°æ®åº“ä¸­"""
        if not self.repository:
            return False

        try:
            # ä½¿ç”¨ç®€å•çš„æŸ¥è¯¢æ£€æŸ¥Pinæ˜¯å¦å­˜åœ¨
            pins = self.repository.load_pins_by_query(query, limit=None)
            return any(pin.get('id') == pin_id for pin in pins)
        except Exception as e:
            logger.error(f"æ£€æŸ¥Pinæ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™: {e}")
            return False







    async def _hybrid_scrape(self, query: str, target_count: int) -> List[Dict]:
        """æ··åˆé‡‡é›†ç­–ç•¥ - æœç´¢ + Pinè¯¦æƒ…é¡µæ·±åº¦æ‰©å±•

        ç­–ç•¥è¯´æ˜ï¼š
        1. ç¬¬ä¸€é˜¶æ®µï¼šå…³é”®è¯æœç´¢ï¼Œæ»šåŠ¨ç›´åˆ°è¿ç»­3æ¬¡æ— æ–°æ•°æ®
        2. ç¬¬äºŒé˜¶æ®µï¼šPinè¯¦æƒ…é¡µæ·±åº¦é‡‡é›†ï¼Œæ¯ä¸ªPinè¯¦æƒ…é¡µæ»šåŠ¨ç›´åˆ°è¿ç»­3æ¬¡æ— æ–°æ•°æ®
        3. å¾ªç¯ç¬¬äºŒé˜¶æ®µï¼Œç›´åˆ°è¿ç»­30ä¸ªPinéƒ½æ— æ³•è·å–æ–°æ•°æ®æ‰é€€å‡º
        """
        logger.info(f"æ‰§è¡Œæ··åˆé‡‡é›†ç­–ç•¥ï¼Œç›®æ ‡: {target_count}")

        # ç¬¬ä¸€é˜¶æ®µï¼šå…³é”®è¯æœç´¢é‡‡é›†
        search_url = f"https://www.pinterest.com/search/pins/?q={query}"
        logger.info(f"ç¬¬ä¸€é˜¶æ®µï¼šå…³é”®è¯æœç´¢ - {search_url}")
        logger.info(f"ç¬¬ä¸€é˜¶æ®µç›®æ ‡: {target_count} ä¸ªå»é‡åå”¯ä¸€Pin")

        # ç¬¬ä¸€é˜¶æ®µç›´æ¥ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ç›®æ ‡æ•°é‡
        # ç§»é™¤ç¡¬ç¼–ç çš„100ä¸ªPinä¸‹é™ï¼Œä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·æŒ‡å®šæ•°é‡é‡‡é›†
        base_pins = await self._search_phase_scrape(search_url, target_count)

        if len(base_pins) >= target_count:
            logger.info(f"ç¬¬ä¸€é˜¶æ®µå·²è¾¾åˆ°ç›®æ ‡ï¼Œè·å¾— {len(base_pins)} ä¸ªPin")
            return base_pins[:target_count]

        logger.info(f"ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼Œè·å¾— {len(base_pins)} ä¸ªPinï¼Œå¼€å§‹Pinè¯¦æƒ…é¡µæ·±åº¦æ‰©å±•")
        
        # ç¬¬äºŒé˜¶æ®µï¼šPinè¯¦æƒ…é¡µæ·±åº¦æ‰©å±•
        all_pins = list(base_pins)
        pin_queue = deque([pin.get('id') for pin in base_pins if pin.get('id')])
        visited_pins = set()
        no_new_data_streak = 0
        max_no_new_data_streak = 30  # è¿ç»­30ä¸ªPinæ— æ–°æ•°æ®æ‰é€€å‡º

        logger.info(f"ç¬¬äºŒé˜¶æ®µï¼šPinè¯¦æƒ…é¡µæ·±åº¦æ‰©å±•ï¼Œåˆå§‹é˜Ÿåˆ—: {len(pin_queue)} ä¸ªPin")

        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(total=target_count, desc="æ·±åº¦é‡‡é›†", unit="pins",
                   initial=len(all_pins), leave=False)

        try:
            while pin_queue and len(all_pins) < target_count and no_new_data_streak < max_no_new_data_streak:
                pin_id = pin_queue.popleft()

                # è·³è¿‡å·²è®¿é—®çš„Pin
                if pin_id in visited_pins:
                    continue

                visited_pins.add(pin_id)

                # é‡‡é›†Pinè¯¦æƒ…é¡µçš„ç›¸å…³æ¨è
                related_pins = await self._scrape_pin_detail_with_queue(pin_id, target_count - len(all_pins))

                if related_pins:
                    # æœ‰æ–°æ•°æ®ï¼Œé‡ç½®è®¡æ•°å™¨
                    no_new_data_streak = 0
                    pins_before = len(all_pins)

                    # å»é‡æ·»åŠ æ–°Pin
                    for related_pin in related_pins:
                        if len(all_pins) >= target_count:
                            break

                        related_id = related_pin.get('id')
                        if related_id and related_id not in self.seen_pin_ids:
                            self.seen_pin_ids.add(related_id)
                            all_pins.append(related_pin)

                            # å°†æ–°PinåŠ å…¥é˜Ÿåˆ—ç”¨äºè¿›ä¸€æ­¥æ‰©å±•
                            if related_id not in visited_pins:
                                pin_queue.append(related_id)

                    new_pins_count = len(all_pins) - pins_before
                    pbar.update(new_pins_count)
                    pbar.set_postfix({
                        "é˜Ÿåˆ—": len(pin_queue),
                        "æ— æ–°æ•°æ®": no_new_data_streak,
                        "å½“å‰Pin": pin_id[:8]
                    })

                    logger.debug(f"Pin {pin_id} è·å¾— {new_pins_count} ä¸ªæ–°Pinï¼Œé˜Ÿåˆ—å‰©ä½™: {len(pin_queue)}")
                else:
                    # æ— æ–°æ•°æ®ï¼Œå¢åŠ è®¡æ•°å™¨
                    no_new_data_streak += 1
                    pbar.set_postfix({
                        "é˜Ÿåˆ—": len(pin_queue),
                        "æ— æ–°æ•°æ®": no_new_data_streak,
                        "å½“å‰Pin": pin_id[:8]
                    })

                    logger.debug(f"Pin {pin_id} æ— æ–°æ•°æ®ï¼Œè¿ç»­æ— æ–°æ•°æ®: {no_new_data_streak}/{max_no_new_data_streak}")

        finally:
            pbar.close()

        # è®°å½•åœæ­¢åŸå› 
        if len(all_pins) >= target_count:
            stop_reason = "è¾¾åˆ°ç›®æ ‡æ•°é‡"
        elif no_new_data_streak >= max_no_new_data_streak:
            stop_reason = f"è¿ç»­ {no_new_data_streak} ä¸ªPinæ— æ–°æ•°æ®"
        elif not pin_queue:
            stop_reason = "Piné˜Ÿåˆ—å·²ç©º"
        else:
            stop_reason = "æœªçŸ¥åŸå› "

        actual_collected = len(all_pins)
        logger.info(f"æ··åˆé‡‡é›†å®Œæˆ: {actual_collected}/{target_count} ({stop_reason})")
        logger.info(f"æ··åˆç­–ç•¥è¯¦æƒ…: ç¬¬ä¸€é˜¶æ®µ {len(base_pins)} + ç¬¬äºŒé˜¶æ®µ {actual_collected - len(base_pins)} = æ€»è®¡ {actual_collected}")

        # è¿”å›å®é™…é‡‡é›†åˆ°çš„æ‰€æœ‰Pinï¼Œä¸æˆªæ–­
        return all_pins

    async def _scrape_pin_detail_with_queue(self, pin_id: str, max_count: int = 50) -> List[Dict]:
        """é‡‡é›†å•ä¸ªPinè¯¦æƒ…é¡µçš„ç›¸å…³æ¨è - å¸¦é˜Ÿåˆ—ç®¡ç†ç‰ˆæœ¬

        å®ç°ç­–ç•¥ï¼š
        1. è®¿é—®Pinè¯¦æƒ…é¡µ
        2. æ»šåŠ¨æ”¶é›†ç›¸å…³æ¨èPin
        3. è¿ç»­3æ¬¡æ— æ–°æ•°æ®æ—¶åœæ­¢
        """
        pin_url = f"https://www.pinterest.com/pin/{pin_id}/"

        # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºæ­£ç¡®æ¸…ç†
        async with NetworkInterceptor(max_cache_size=max_count * 2, verbose=False, target_count=0) as interceptor:
            browser = BrowserManager(
                proxy=self.proxy,
                timeout=30,
                cookie_path=self.cookie_path,
                headless=True,
                enable_network_interception=True
            )

            try:
                if not await browser.start():
                    return []

                browser.add_request_handler(interceptor._handle_request)
                browser.add_response_handler(interceptor._handle_response)

                if not await browser.navigate(pin_url):
                    return []

                # é¡µé¢åŠ è½½åçš„äººç±»è¡Œä¸ºå»¶è¿Ÿ
                import random
                await asyncio.sleep(random.uniform(2.0, 4.0))

                # æ»šåŠ¨è·å–ç›¸å…³æ¨èï¼Œç›´åˆ°è¿ç»­3æ¬¡æ— æ–°æ•°æ®
                consecutive_no_new = 0
                max_consecutive = 3
                scroll_count = 0
                max_scrolls = 20  # æœ€å¤§æ»šåŠ¨æ¬¡æ•°

                while (len(interceptor.extracted_pins) < max_count and
                       consecutive_no_new < max_consecutive and
                       scroll_count < max_scrolls):

                    pins_before = len(interceptor.extracted_pins)

                    # æ»šåŠ¨é¡µé¢
                    await browser.page.evaluate("window.scrollBy(0, window.innerHeight)")
                    # æ»šåŠ¨åçš„äººç±»è¡Œä¸ºå»¶è¿Ÿ
                    await asyncio.sleep(random.uniform(1.5, 3.0))
                    scroll_count += 1

                    # ç­‰å¾…é¡µé¢åŠ è½½
                    try:
                        await browser.page.wait_for_load_state('networkidle', timeout=3000)
                    except:
                        pass

                    pins_after = len(interceptor.extracted_pins)

                    if pins_after > pins_before:
                        consecutive_no_new = 0
                    else:
                        consecutive_no_new += 1

                result_pins = list(interceptor.extracted_pins)[:max_count]
                logger.debug(f"Pin {pin_id} è¯¦æƒ…é¡µé‡‡é›†: {len(result_pins)} ä¸ªç›¸å…³Pin (æ»šåŠ¨ {scroll_count} æ¬¡)")

                return result_pins

            except Exception as e:
                logger.debug(f"Pinè¯¦æƒ…é¡µé‡‡é›†å‡ºé”™: {e}")
                return []
            finally:
                await browser.stop()
                # NetworkInterceptorä¼šåœ¨async withé€€å‡ºæ—¶è‡ªåŠ¨æ¸…ç†

    async def _scrape_pin_detail(self, pin_id: str, max_count: int = 50) -> List[Dict]:
        """é‡‡é›†å•ä¸ªPinè¯¦æƒ…é¡µçš„ç›¸å…³æ¨è - å…¼å®¹æ€§æ–¹æ³•"""
        return await self._scrape_pin_detail_with_queue(pin_id, max_count)

    def _build_url(self, query: Optional[str], url: Optional[str]) -> Optional[str]:
        """æ„å»ºç›®æ ‡URL"""
        if url:
            return url
        elif query:
            return f"https://www.pinterest.com/search/pins/?q={query}"
        else:
            return None

    def _reset_state(self):
        """é‡ç½®é‡‡é›†çŠ¶æ€"""
        self.collected_pins.clear()
        self.seen_pin_ids.clear()
        self._interrupt_requested = False
        self._saved_count = 0
        self._baseline_count = 0  # é‡‡é›†åŸºå‡†æ•°é‡
        self.stats = {
            "total_scrolls": 0,
            "api_calls_intercepted": 0,
            "html_extractions": 0,
            "duplicates_filtered": 0,
            "pins_saved_realtime": 0
        }

    def get_stats(self) -> Dict:
        """è·å–é‡‡é›†ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()

    def _deduplicate_pins(self, pins: List[Dict]) -> List[Dict]:
        """å»é‡å¤„ç†Pinæ•°æ®

        Args:
            pins: Pinæ•°æ®åˆ—è¡¨

        Returns:
            å»é‡åçš„Pinæ•°æ®åˆ—è¡¨
        """
        seen_ids = set()
        unique_pins = []
        duplicates_count = 0
        no_id_count = 0

        for pin in pins:
            pin_id = pin.get('id')
            if pin_id and pin_id not in seen_ids:
                seen_ids.add(pin_id)
                unique_pins.append(pin)
            elif pin_id:
                duplicates_count += 1
            else:
                no_id_count += 1

        # è¯¦ç»†çš„å»é‡ç»Ÿè®¡
        total_input = len(pins)
        if total_input > 0:
            dedup_rate = duplicates_count / total_input * 100
            if duplicates_count > 0:
                logger.debug(f"å»é‡ç»Ÿè®¡: è¾“å…¥ {total_input}, è¾“å‡º {len(unique_pins)}, é‡å¤ {duplicates_count} ({dedup_rate:.1f}%), æ— ID {no_id_count}")
            self.stats["duplicates_filtered"] += duplicates_count

        return unique_pins

    async def _search_phase_scrape(self, url: str, target_count: int) -> List[Dict]:
        """æœç´¢é˜¶æ®µé‡‡é›† - åŸºç¡€æ»šåŠ¨é‡‡é›†

        Args:
            url: æœç´¢URL
            target_count: ç›®æ ‡æ•°é‡

        Returns:
            é‡‡é›†åˆ°çš„Pinæ•°æ®åˆ—è¡¨
        """
        browser = BrowserManager(
            proxy=self.proxy,
            timeout=self.timeout,
            cookie_path=self.cookie_path,
            headless=True
        )

        try:
            if not await browser.start():
                return []

            if not await browser.navigate(url):
                return []

            time.sleep(config.INITIAL_WAIT_TIME)

            # æ»šåŠ¨ç­–ç•¥ï¼šåŸºäºç›®æ ‡æ•°é‡åŠ¨æ€è°ƒæ•´
            min_scrolls = 10
            max_scrolls = max(target_count * 3, min_scrolls)
            no_new_data_limit = 10

            logger.debug(f"æœç´¢é˜¶æ®µæ»šåŠ¨ç­–ç•¥: è¿ç»­{no_new_data_limit}æ¬¡æ— æ–°æ•°æ®åœæ­¢ï¼Œæœ€å¤§æ»šåŠ¨{max_scrolls}æ¬¡")

            # æ»šåŠ¨æ”¶é›†
            pins = await browser.scroll_and_collect(
                target_count=target_count,
                extract_func=extract_pins_from_html,
                max_scrolls=max_scrolls,
                scroll_pause=1.5,
                no_new_data_limit=no_new_data_limit,
                initial_count=self._baseline_count
            )

            self.stats["total_scrolls"] = max_scrolls
            self.stats["html_extractions"] = len(pins)

            return pins

        except Exception as e:
            logger.error(f"æœç´¢é˜¶æ®µé‡‡é›†å‡ºé”™: {e}")
            return []

    async def _handle_interrupt(self, query: Optional[str]):
        """å¤„ç†ç”¨æˆ·ä¸­æ–­ï¼Œæ•°æ®å·²å®æ—¶ä¿å­˜"""
        if self.repository and query:
            try:
                logger.info(f"ä¸­æ–­å¤„ç†å®Œæˆï¼Œå·²å®æ—¶ä¿å­˜ {self._saved_count} ä¸ªPin")

                # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸ºä¸­æ–­
                if self.session_id:
                    self.repository.update_session_status(
                        self.session_id, 'interrupted', self._saved_count
                    )
                    logger.info(f"ä¼šè¯çŠ¶æ€å·²æ›´æ–°ä¸ºä¸­æ–­: {self.session_id}")

            except Exception as e:
                logger.error(f"ä¸­æ–­å¤„ç†å¤±è´¥: {e}")
        else:
            logger.warning("æ— Repositoryæˆ–queryï¼Œæ— æ³•æ›´æ–°ä¸­æ–­çŠ¶æ€")

    def request_interrupt(self):
        """è¯·æ±‚ä¸­æ–­é‡‡é›†ï¼ˆç”¨äºå¤–éƒ¨è°ƒç”¨ï¼‰"""
        self._interrupt_requested = True
        logger.info("å·²è¯·æ±‚ä¸­æ–­é‡‡é›†")

    def get_saved_count(self) -> int:
        """è·å–å·²ä¿å­˜çš„Pinæ•°é‡"""
        return self._saved_count

    async def close(self):
        """å…³é—­æ™ºèƒ½é‡‡é›†å™¨ï¼Œæ¸…ç†æµè§ˆå™¨èµ„æº"""
        try:
            logger.debug("æ­£åœ¨æ¸…ç†æ™ºèƒ½é‡‡é›†å™¨èµ„æº...")
            # SmartScraperæœ¬èº«ä¸æŒæœ‰é•¿æœŸçš„æµè§ˆå™¨å®ä¾‹
            # æµè§ˆå™¨å®ä¾‹åœ¨æ¯ä¸ªæ–¹æ³•ä¸­åˆ›å»ºå’Œé”€æ¯
            # è¿™é‡Œä¸»è¦æ˜¯ä¸ºäº†æ¥å£ä¸€è‡´æ€§
            logger.debug("æ™ºèƒ½é‡‡é›†å™¨èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"æ¸…ç†æ™ºèƒ½é‡‡é›†å™¨èµ„æºæ—¶å‡ºé”™: {e}")
