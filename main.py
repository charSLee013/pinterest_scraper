#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Pinterestçˆ¬è™«ä¸»ç¨‹åº

é›†æˆå¼‚æ­¥ä¸‹è½½çš„Pinterestæ•°æ®é‡‡é›†å·¥å…·ï¼Œä¸€ç«™å¼å®Œæˆæ•°æ®é‡‡é›†å’Œå›¾ç‰‡ä¸‹è½½
"""

import argparse
import sys
import asyncio
import signal

from loguru import logger
from src.core.pinterest_scraper import PinterestScraper


def setup_signal_handlers():
    """è®¾ç½®ä¿¡å·å¤„ç†å™¨ä»¥ä¼˜é›…å¤„ç†ä¸­æ–­"""
    def signal_handler(signum, frame):
        logger.info(f"æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
        # ä¸ç›´æ¥é€€å‡ºï¼Œè®©KeyboardInterruptå¼‚å¸¸å¤„ç†
        raise KeyboardInterrupt()

    # åœ¨Windowså’ŒUnixç³»ç»Ÿä¸Šè®¾ç½®ä¿¡å·å¤„ç†
    if sys.platform != 'win32':
        signal.signal(signal.SIGTERM, signal_handler)
        signal.signal(signal.SIGINT, signal_handler)
    else:
        # Windowsåªæ”¯æŒSIGINT
        signal.signal(signal.SIGINT, signal_handler)


def create_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="Pinterestæ™ºèƒ½çˆ¬è™« - é›†æˆå¼‚æ­¥ä¸‹è½½çš„æ•°æ®é‡‡é›†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python main.py --query "nature photography" --count 100
  python main.py --url "https://www.pinterest.com/pinterest/" --count 50
  python main.py --query "landscape" --count 2000 --max-concurrent 30
  python main.py --query "cats" --count 100 --no-images  # ä»…é‡‡é›†æ•°æ®ï¼Œä¸ä¸‹è½½å›¾ç‰‡
  python main.py --only-images --query "cats"  # ä»…ä¸‹è½½catså…³é”®è¯çš„ç¼ºå¤±å›¾ç‰‡
  python main.py --only-images --max-concurrent 25  # ä¸‹è½½æ‰€æœ‰å…³é”®è¯ï¼Œé«˜å¹¶å‘
  python main.py --only-images -j 5  # ä¸‹è½½æ‰€æœ‰å…³é”®è¯ï¼Œä½å¹¶å‘ï¼ˆç½‘ç»œæ…¢æ—¶ï¼‰
        """
    )

    # æ•°æ®æºå‚æ•°ï¼ˆäº’æ–¥ï¼Œä½†--only-imagesæ¨¡å¼ä¸‹å¯é€‰ï¼‰
    source_group = parser.add_mutually_exclusive_group(required=False)
    source_group.add_argument(
        "-q", "--query",
        help="Pinterestæœç´¢å…³é”®è¯"
    )
    source_group.add_argument(
        "-u", "--url",
        help="Pinterest URL"
    )

    # æ ¸å¿ƒå‚æ•°
    parser.add_argument(
        "-c", "--count",
        type=int,
        default=50,
        help="ç›®æ ‡é‡‡é›†æ•°é‡ (é»˜è®¤: 50ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥)"
    )
    parser.add_argument(
        "-o", "--output",
        default="output",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: output)"
    )

    # ç®€åŒ–çš„å¯é€‰å‚æ•°
    parser.add_argument(
        "--no-images",
        action="store_true",
        help="ä»…è·å–å…ƒæ•°æ®ï¼Œä¸ä¸‹è½½å›¾ç‰‡"
    )
    parser.add_argument(
        "--only-images",
        action="store_true",
        help="ä»…ä¸‹è½½å›¾ç‰‡æ¨¡å¼ï¼šä»ç°æœ‰æ•°æ®åº“ä¸­ä¸‹è½½ç¼ºå¤±çš„å›¾ç‰‡"
    )
    parser.add_argument(
        "--proxy",
        help="ä»£ç†æœåŠ¡å™¨"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆæ˜¾ç¤ºæµè§ˆå™¨ï¼‰"
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="å¯ç”¨è¯¦ç»†è¾“å‡ºï¼ˆå¼€å‘æ¨¡å¼ï¼‰"
    )
    parser.add_argument(
        "--max-concurrent", "--max-workers", "-j",
        type=int,
        default=15,
        help="æœ€å¤§å¹¶å‘ä¸‹è½½æ•° (é»˜è®¤: 15ï¼ŒèŒƒå›´: 1-50)"
    )

    return parser


def validate_concurrent_value(value: int) -> int:
    """éªŒè¯å¹¶å‘æ•°å€¼çš„æœ‰æ•ˆæ€§"""
    if value < 1:
        logger.warning(f"å¹¶å‘æ•°è¿‡å° ({value})ï¼Œè®¾ç½®ä¸º1")
        return 1
    elif value > 50:
        logger.warning(f"å¹¶å‘æ•°è¿‡å¤§ ({value})ï¼Œè®¾ç½®ä¸º50")
        return 50
    return value


def setup_logger(debug: bool = False, verbose: bool = False):
    """è®¾ç½®ä¸‰å±‚æ—¥å¿—é…ç½®

    Args:
        debug: å¯ç”¨DEBUGçº§åˆ«ï¼ˆè°ƒè¯•å±‚ï¼‰
        verbose: å¯ç”¨INFOçº§åˆ«ï¼ˆå¼€å‘å±‚ï¼‰
        é»˜è®¤: WARNINGçº§åˆ«ï¼ˆç”¨æˆ·å±‚ï¼‰
    """
    logger.remove()
    if debug:
        level = "DEBUG"
    elif verbose:
        level = "INFO"
    else:
        level = "WARNING"

    logger.add(
        sys.stderr,
        format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}",
        level=level,
        colorize=True
    )

async def async_main():
    """å¼‚æ­¥ä¸»å‡½æ•° - æ”¯æŒèµ„æºæ¸…ç†"""
    parser = create_parser()
    args = parser.parse_args()

    # å‚æ•°éªŒè¯
    if args.only_images:
        # --only-imagesæ¨¡å¼ä¸‹ï¼Œä¸éœ€è¦--queryæˆ–--url
        if args.no_images:
            logger.error("--only-images å’Œ --no-images ä¸èƒ½åŒæ—¶ä½¿ç”¨")
            return 1
        if args.url:
            logger.error("--only-images æ¨¡å¼ä¸‹ä¸æ”¯æŒ --url å‚æ•°")
            return 1
    else:
        # æ™®é€šæ¨¡å¼ä¸‹ï¼Œå¿…é¡»æä¾›--queryæˆ–--url
        if not args.query and not args.url:
            logger.error("å¿…é¡»æä¾› --query æˆ– --url å‚æ•°ï¼ˆé™¤éä½¿ç”¨ --only-images æ¨¡å¼ï¼‰")
            return 1

    # è®¾ç½®æ—¥å¿—
    setup_logger(args.debug, args.verbose)

    # éªŒè¯å¹¶å‘å‚æ•°
    max_concurrent = validate_concurrent_value(args.max_concurrent)

    # --only-images æ¨¡å¼ï¼šä¸‰é˜¶æ®µä¼˜åŒ–å¤„ç†ï¼ˆBase64è½¬æ¢ + Headerå‡†å¤‡ + æ™ºèƒ½ä¸‹è½½ï¼‰
    if args.only_images:
        from src.tools.optimized_only_images_workflow import OptimizedOnlyImagesWorkflow

        logger.info("ğŸš€ å¼€å§‹ä¸‰é˜¶æ®µä¼˜åŒ–--only-imageså¤„ç†æµç¨‹")
        logger.info("Phase 1: å®æ—¶Base64è½¬æ¢")
        logger.info("Phase 2: å…¨å±€Headerå‡†å¤‡")
        logger.info("Phase 3: æ™ºèƒ½ä¸‹è½½ï¼ˆæŒ‰éœ€Pinå¢å¼ºï¼‰")

        # åˆ›å»ºä¼˜åŒ–åçš„å·¥ä½œæµç¨‹
        workflow = OptimizedOnlyImagesWorkflow(
            output_dir=args.output,
            max_concurrent=max_concurrent,
            proxy=args.proxy
        )

        try:
            # æ‰§è¡Œä¼˜åŒ–åçš„ä¸‰é˜¶æ®µå·¥ä½œæµç¨‹
            if args.query:
                logger.info(f"ğŸ¯ ç›®æ ‡å…³é”®è¯: {args.query}")
            else:
                logger.info("ğŸ¯ å¤„ç†æ‰€æœ‰å…³é”®è¯")

            # æ‰§è¡Œå·¥ä½œæµç¨‹
            result = await workflow.execute(target_keyword=args.query)

            if result["status"] == "success":
                logger.info("ğŸ‰ ä¸‰é˜¶æ®µå·¥ä½œæµç¨‹æ‰§è¡ŒæˆåŠŸ")

                # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
                stats = result.get("stats", {})

                # Phase 1 ç»Ÿè®¡
                phase1_stats = stats.get("phase1_base64_conversion", {})
                if phase1_stats.get("total_converted", 0) > 0:
                    logger.info(f"ğŸ“Š Phase 1: è½¬æ¢äº† {phase1_stats['total_converted']} ä¸ªbase64ç¼–ç Pin")

                # Phase 2 ç»Ÿè®¡
                phase2_stats = stats.get("phase2_header_preparation", {})
                if phase2_stats.get("valid", False):
                    logger.info(f"ğŸ“Š Phase 2: Headerså‡†å¤‡æˆåŠŸ ({phase2_stats.get('count', 0)} ä¸ªå­—æ®µ)")

                # Phase 3 ç»Ÿè®¡
                phase3_stats = stats.get("phase3_smart_download", {})
                if phase3_stats:
                    logger.info(f"ğŸ“Š Phase 3: ä¸‹è½½ç»Ÿè®¡ {phase3_stats}")

                # æ€»æ‰§è¡Œæ—¶é—´
                total_time = stats.get("total_execution_time", 0)
                logger.info(f"â±ï¸ æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f} ç§’")

                return 0
            else:
                logger.error(f"âŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return 1

        except Exception as e:
            logger.error(f"ä¼˜åŒ–å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            if args.debug:
                import traceback
                logger.error(traceback.format_exc())
            return 1

    # æ™®é€šæ¨¡å¼ï¼šæ•°æ®é‡‡é›†
    scraper = None
    try:
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        scraper = PinterestScraper(
            output_dir=args.output,
            download_images=not args.no_images,
            proxy=args.proxy,
            debug=args.debug,
            max_concurrent=max_concurrent
        )

        # æ‰§è¡Œæ™ºèƒ½é‡‡é›†
        pins = await scraper.scrape(
            query=args.query,
            url=args.url,
            count=args.count
        )

        # è¾“å‡ºç»“æœ
        if pins:
            logger.warning(f"é‡‡é›†å®Œæˆ: {len(pins)} ä¸ªPin -> {args.output}")

            # å¦‚æœå¯ç”¨äº†å›¾ç‰‡ä¸‹è½½ï¼Œç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆ
            if not args.no_images:
                logger.debug("å¼€å§‹å¼‚æ­¥ä¸‹è½½å›¾ç‰‡...")

                # è·å–ä¸‹è½½ç»Ÿè®¡ä¿¡æ¯
                stats = scraper.get_stats()
                if 'download_stats' in stats:
                    download_stats = stats['download_stats']
                    total_tasks = download_stats.get('total_tasks', 0)

                    if total_tasks > 0:
                        logger.debug(f"å¼€å§‹ä¸‹è½½ {total_tasks} å¼ å›¾ç‰‡...")

                        # ç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆ
                        try:
                            await scraper.wait_for_downloads_completion()

                            # è·å–æœ€ç»ˆç»Ÿè®¡
                            final_stats = scraper.get_stats()
                            if 'download_stats' in final_stats:
                                final_download_stats = final_stats['download_stats']
                                completed = final_download_stats.get('completed', 0)
                                failed = final_download_stats.get('failed', 0)
                                logger.warning(f"å›¾ç‰‡ä¸‹è½½å®Œæˆ: {completed} æˆåŠŸ, {failed} å¤±è´¥")
                            else:
                                logger.warning("å›¾ç‰‡ä¸‹è½½å®Œæˆ")

                        except KeyboardInterrupt:
                            logger.info("ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
                        except Exception as e:
                            logger.error(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                    else:
                        logger.debug("æ²¡æœ‰å›¾ç‰‡éœ€è¦ä¸‹è½½")
        else:
            logger.error("é‡‡é›†å¤±è´¥ï¼Œæœªè·å–åˆ°æ•°æ®")
            return 1

    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        logger.error(f"å‘ç”Ÿé”™è¯¯: {e}")
        if args.debug:
            import traceback
            logger.error(traceback.format_exc())
        return 1
    finally:
        # ç¡®ä¿èµ„æºæ¸…ç†
        if scraper:
            try:
                logger.debug("æ­£åœ¨æ¸…ç†èµ„æº...")
                await scraper.close()
                logger.debug("èµ„æºæ¸…ç†å®Œæˆ")
            except Exception as e:
                logger.error(f"èµ„æºæ¸…ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    return 0


def main():
    """ä¸»å‡½æ•°å…¥å£ - è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°"""
    try:
        # è®¾ç½®ä¿¡å·å¤„ç†å™¨
        setup_signal_handlers()

        # åœ¨Windowsä¸Šä½¿ç”¨æ›´ç¨³å®šçš„äº‹ä»¶å¾ªç¯ç­–ç•¥
        if sys.platform == 'win32':
            # è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ä»¥å‡å°‘æ¸…ç†è­¦å‘Š
            asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

        return asyncio.run(async_main())
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    finally:
        # åœ¨Windowsä¸Šæ˜¾å¼æ¸…ç†äº‹ä»¶å¾ªç¯ä»¥å‡å°‘è­¦å‘Š
        if sys.platform == 'win32':
            try:
                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©å¼‚æ­¥ä»»åŠ¡å®Œæˆæ¸…ç†
                import time
                time.sleep(0.2)

                # å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼Œæ¸…ç†æœªå…³é—­çš„èµ„æº
                import gc
                gc.collect()

                # ç­‰å¾…æ›´é•¿æ—¶é—´è®©å­è¿›ç¨‹å®Œå…¨é€€å‡º
                time.sleep(0.3)

            except Exception:
                # å¿½ç•¥æ¸…ç†æ—¶çš„å¼‚å¸¸ï¼Œè¿™äº›é€šå¸¸æ˜¯æ— å®³çš„
                pass


if __name__ == "__main__":
    sys.exit(main())
