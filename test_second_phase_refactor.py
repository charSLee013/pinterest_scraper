#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æµ‹è¯•ç¬¬äºŒé˜¶æ®µé‡æ„åçš„é€»è¾‘
éªŒè¯æ–°çš„ç¬¬äºŒé˜¶æ®µå®ç°æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
import asyncio
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.core.smart_scraper import SmartScraper
from src.core.database.repository import SQLiteRepository
from loguru import logger
import uuid

async def test_second_phase_refactor():
    """æµ‹è¯•é‡æ„åçš„ç¬¬äºŒé˜¶æ®µé€»è¾‘"""
    logger.info("=== æµ‹è¯•ç¬¬äºŒé˜¶æ®µé‡æ„é€»è¾‘ ===")
    
    # åˆå§‹åŒ–Repositoryå’ŒSmartScraper
    repo = SQLiteRepository(keyword="cat", output_dir="output")
    session_id = f"test_refactor_{uuid.uuid4().hex[:8]}"
    
    scraper = SmartScraper(
        repository=repo,
        session_id=session_id,
        debug=True
    )
    
    # æµ‹è¯•å‚æ•°
    query = "cat"
    target_count = 10  # å°æ•°é‡æµ‹è¯•
    
    logger.info(f"å¼€å§‹æµ‹è¯•ï¼Œç›®æ ‡: {target_count} ä¸ªPin")
    
    try:
        # æ‰§è¡Œé‡‡é›†
        pins = await scraper.scrape(
            query=query,
            target_count=target_count,
            repository=repo,
            session_id=session_id
        )
        
        logger.info(f"é‡‡é›†å®Œæˆï¼Œè·å¾— {len(pins)} ä¸ªPin")
        
        # éªŒè¯ç»“æœ
        if pins:
            logger.info("âœ… ç¬¬äºŒé˜¶æ®µé‡æ„æµ‹è¯•æˆåŠŸ")
            
            # æ˜¾ç¤ºå‰3ä¸ªPinçš„ä¿¡æ¯
            for i, pin in enumerate(pins[:3], 1):
                logger.info(f"Pin {i}:")
                logger.info(f"  ID: {pin.get('id', 'N/A')}")
                logger.info(f"  æ ‡é¢˜: {pin.get('title', 'N/A')[:50]}...")
                logger.info(f"  æœ‰å›¾ç‰‡URL: {bool(pin.get('largest_image_url'))}")
            
            # æ£€æŸ¥æ•°æ®åº“ä¸­çš„æ•°æ®
            db_pins = repo.load_pins_with_images(query, limit=20)
            logger.info(f"æ•°æ®åº“ä¸­æœ‰å›¾ç‰‡çš„Pinæ•°é‡: {len(db_pins)}")
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = scraper.get_stats()
            logger.info(f"é‡‡é›†ç»Ÿè®¡: {stats}")
            
        else:
            logger.warning("âš ï¸ æœªè·å–åˆ°Pinæ•°æ®")
            
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        await scraper.close()

async def test_database_driven_expansion():
    """æµ‹è¯•æ•°æ®åº“é©±åŠ¨çš„æ‰©å±•é€»è¾‘"""
    logger.info("\n=== æµ‹è¯•æ•°æ®åº“é©±åŠ¨æ‰©å±•é€»è¾‘ ===")
    
    repo = SQLiteRepository(keyword="cat", output_dir="output")
    
    # 1. æ£€æŸ¥æ•°æ®åº“ä¸­æœ‰å›¾ç‰‡çš„pins
    pins_with_images = repo.load_pins_with_images("cat", limit=10)
    logger.info(f"æ•°æ®åº“ä¸­æœ‰å›¾ç‰‡çš„Pinæ•°é‡: {len(pins_with_images)}")
    
    if pins_with_images:
        # 2. æ¨¡æ‹Ÿä»setä¸­popä¸€ä¸ªpin
        pin_set = set([pin['id'] for pin in pins_with_images])
        logger.info(f"Pin setå¤§å°: {len(pin_set)}")
        
        if pin_set:
            test_pin_id = pin_set.pop()
            logger.info(f"æµ‹è¯•Pin ID: {test_pin_id}")
            
            # 3. æ¨¡æ‹Ÿä¿å­˜æ–°pinså¹¶è·å–æ–°å¢id
            test_new_pins = [
                {
                    'id': f'expansion_test_{uuid.uuid4().hex[:8]}',
                    'title': f'æ‰©å±•æµ‹è¯•Pin for {test_pin_id}',
                    'description': 'æ•°æ®åº“é©±åŠ¨æ‰©å±•æµ‹è¯•',
                    'largest_image_url': 'https://example.com/expansion_test.jpg',
                    'image_urls': {'1': 'expansion_url1'}
                }
            ]
            
            session_id = f"expansion_test_{uuid.uuid4().hex[:8]}"
            new_pin_ids = repo.save_pins_and_get_new_ids(test_new_pins, "cat", session_id)
            
            logger.info(f"æ–°å¢Pin IDs: {new_pin_ids}")
            
            if new_pin_ids:
                # 4. å°†æ–°pin idåŠ å…¥set
                pin_set.update(new_pin_ids)
                logger.info(f"æ›´æ–°åPin setå¤§å°: {len(pin_set)}")
                logger.info("âœ… æ•°æ®åº“é©±åŠ¨æ‰©å±•é€»è¾‘æµ‹è¯•æˆåŠŸ")
            else:
                logger.warning("âš ï¸ æœªè·å¾—æ–°å¢Pin ID")
        else:
            logger.warning("âš ï¸ Pin setä¸ºç©º")
    else:
        logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰æœ‰å›¾ç‰‡çš„Pin")

async def test_new_methods():
    """æµ‹è¯•æ–°çš„Repositoryæ–¹æ³•"""
    logger.info("\n=== æµ‹è¯•æ–°çš„Repositoryæ–¹æ³• ===")
    
    repo = SQLiteRepository(keyword="cat", output_dir="output")
    
    # æµ‹è¯•load_pins_with_images
    pins = repo.load_pins_with_images("cat", limit=5)
    logger.info(f"load_pins_with_images: {len(pins)} ä¸ªPin")
    
    if pins:
        logger.info(f"ç¬¬ä¸€ä¸ªPin: {pins[0]['id']}")
        logger.info(f"æœ‰largest_image_url: {bool(pins[0].get('largest_image_url'))}")
        logger.info(f"æœ‰image_urls: {bool(pins[0].get('image_urls'))}")
    
    # æµ‹è¯•save_pins_and_get_new_ids
    test_pins = [
        {
            'id': f'method_test_{uuid.uuid4().hex[:8]}',
            'title': 'æ–¹æ³•æµ‹è¯•Pin',
            'description': 'æµ‹è¯•save_pins_and_get_new_idsæ–¹æ³•',
            'largest_image_url': 'https://example.com/method_test.jpg',
            'image_urls': {'1': 'method_test_url1'}
        }
    ]
    
    session_id = f"method_test_{uuid.uuid4().hex[:8]}"
    new_ids = repo.save_pins_and_get_new_ids(test_pins, "cat", session_id)
    logger.info(f"save_pins_and_get_new_ids: {new_ids}")
    
    if new_ids:
        logger.info("âœ… æ–°æ–¹æ³•æµ‹è¯•æˆåŠŸ")
    else:
        logger.warning("âš ï¸ æ–°æ–¹æ³•æµ‹è¯•å¤±è´¥")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    try:
        # æµ‹è¯•æ–°çš„Repositoryæ–¹æ³•
        await test_new_methods()
        
        # æµ‹è¯•æ•°æ®åº“é©±åŠ¨æ‰©å±•é€»è¾‘
        await test_database_driven_expansion()
        
        # æµ‹è¯•å®Œæ•´çš„ç¬¬äºŒé˜¶æ®µé‡æ„é€»è¾‘
        await test_second_phase_refactor()
        
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
