#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Pinterest Scraper IntegrityErrorä¿®å¤éªŒè¯é›†æˆæµ‹è¯•
éªŒè¯å®Œæ•´çš„ä¿®å¤æ–¹æ¡ˆåœ¨çœŸå®åœºæ™¯ä¸‹çš„æ•ˆæœ
"""

import os
import sys
import time
import tempfile
import threading
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.core.database.base import initialize_database
from src.core.database.repository import SQLiteRepository
from src.core.process_manager import ProcessManager
from src.core.database.migrate_indexes import migrate_database


class IntegrityErrorFixVerification:
    """IntegrityErrorä¿®å¤éªŒè¯å™¨"""
    
    def __init__(self):
        self.test_dir = "integration_test_verification"
        self.setup_test_environment()
    
    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        os.makedirs(self.test_dir, exist_ok=True)
        print(f"æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ: {self.test_dir}")
    
    def cleanup_test_environment(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        try:
            import shutil
            if os.path.exists(self.test_dir):
                shutil.rmtree(self.test_dir)
            print("æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†æµ‹è¯•ç¯å¢ƒå¤±è´¥: {e}")
    
    def test_original_integrity_error_scenario(self) -> bool:
        """æµ‹è¯•åŸå§‹IntegrityErroråœºæ™¯ï¼ˆåº”è¯¥å·²ä¿®å¤ï¼‰"""
        print("\n=== æµ‹è¯•åŸå§‹IntegrityErroråœºæ™¯ ===")
        
        db_path = os.path.join(self.test_dir, "original_scenario.db")
        
        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            initialize_database(db_path)
            migrate_database(db_path)
            
            # æ¨¡æ‹Ÿç”¨æˆ·æŠ¥å‘Šçš„é”™è¯¯åœºæ™¯ï¼šå¤šæ¬¡ä¸­æ–­é‡å¯
            def simulate_interrupted_process(process_id):
                """æ¨¡æ‹Ÿè¢«ä¸­æ–­çš„è¿›ç¨‹"""
                repository = SQLiteRepository()
                
                # æ¨¡æ‹Ÿç”¨æˆ·æŠ¥å‘Šçš„Pinæ•°æ®
                pin_data = {
                    'id': '76561262410443623',  # ç”¨æˆ·æŠ¥å‘Šçš„Pin ID
                    'title': f"Process {process_id} - an artist's rendering of a house with a swimming pool",
                    'description': "an artist's rendering of a house with a swimming pool in the foreground",
                    'largest_image_url': 'https://i.pinimg.com/originals/2a/71/dd/2a71dd763197e1bbfceda6f1104ea7d4.jpg',
                    'image_urls': {
                        "1": "https://i.pinimg.com/236x/2a/71/dd/2a71dd763197e1bbfceda6f1104ea7d4.jpg",
                        "2": "https://i.pinimg.com/474x/2a/71/dd/2a71dd763197e1bbfceda6f1104ea7d4.jpg",
                        "4": "https://i.pinimg.com/originals/2a/71/dd/2a71dd763197e1bbfceda6f1104ea7d4.jpg"
                    }
                }
                
                # å°è¯•ä¿å­˜ï¼ˆåœ¨ä¿®å¤å‰ä¼šå¯¼è‡´IntegrityErrorï¼‰
                result = repository.save_pins_batch([pin_data], 'building')
                print(f"Process {process_id} ä¿å­˜ç»“æœ: {result}")
                return result
            
            # æ¨¡æ‹Ÿå¤šä¸ª"é‡å¯"è¿›ç¨‹åŒæ—¶å¤„ç†ç›¸åŒæ•°æ®
            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = [executor.submit(simulate_interrupted_process, i) for i in range(5)]
                results = [future.result() for future in futures]
            
            # éªŒè¯ç»“æœ
            repository = SQLiteRepository()
            pins = repository.load_pins_by_query('building')
            
            print(f"æ¨¡æ‹Ÿé‡å¯è¿›ç¨‹ç»“æœ: {results}")
            print(f"æœ€ç»ˆPinæ•°é‡: {len(pins)}")
            print(f"æ‰€æœ‰æ“ä½œæˆåŠŸ: {all(results)}")
            
            # éªŒè¯ï¼šæ‰€æœ‰æ“ä½œéƒ½æˆåŠŸï¼Œæ²¡æœ‰IntegrityError
            assert all(results), "æ‰€æœ‰æ“ä½œéƒ½åº”è¯¥æˆåŠŸï¼ˆæ— IntegrityErrorï¼‰"
            assert len(pins) == 1, "åº”è¯¥åªæœ‰ä¸€ä¸ªPinï¼ˆå»é‡æˆåŠŸï¼‰"
            
            print("âœ… åŸå§‹IntegrityErroråœºæ™¯ä¿®å¤éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ åŸå§‹åœºæ™¯æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_process_manager_integration(self) -> bool:
        """æµ‹è¯•è¿›ç¨‹ç®¡ç†å™¨é›†æˆ"""
        print("\n=== æµ‹è¯•è¿›ç¨‹ç®¡ç†å™¨é›†æˆ ===")
        
        try:
            def worker_with_process_manager(worker_id):
                """ä½¿ç”¨è¿›ç¨‹ç®¡ç†å™¨çš„å·¥ä½œè¿›ç¨‹"""
                manager = ProcessManager("integration_test", self.test_dir)
                
                if manager.acquire_lock():
                    try:
                        # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
                        repository = SQLiteRepository()
                        pin_data = {
                            'id': f'process_manager_pin_{worker_id}',
                            'title': f'Process Manager Pin {worker_id}',
                            'largest_image_url': f'https://example.com/pm_{worker_id}.jpg'
                        }
                        
                        result = repository.save_pins_batch([pin_data], 'process_manager_test')
                        time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                        
                        return {'worker_id': worker_id, 'acquired_lock': True, 'save_result': result}
                    finally:
                        manager.release_lock()
                else:
                    return {'worker_id': worker_id, 'acquired_lock': False, 'save_result': False}
            
            # å¯åŠ¨å¤šä¸ªè¿›ç¨‹å°è¯•è·å–é”
            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = [executor.submit(worker_with_process_manager, i) for i in range(5)]
                results = [future.result() for future in futures]
            
            # åˆ†æç»“æœ
            acquired_count = sum(1 for r in results if r['acquired_lock'])
            successful_saves = sum(1 for r in results if r['save_result'])
            
            print(f"è¿›ç¨‹ç®¡ç†å™¨ç»“æœ: {results}")
            print(f"è·å–é”çš„è¿›ç¨‹æ•°: {acquired_count}")
            print(f"æˆåŠŸä¿å­˜çš„è¿›ç¨‹æ•°: {successful_saves}")
            
            # éªŒè¯æ•°æ®
            repository = SQLiteRepository()
            pins = repository.load_pins_by_query('process_manager_test')
            print(f"æœ€ç»ˆPinæ•°é‡: {len(pins)}")
            
            # éªŒè¯ï¼šè‡³å°‘æœ‰ä¸€ä¸ªè¿›ç¨‹è·å–é”å¹¶æˆåŠŸä¿å­˜
            assert acquired_count >= 1, "è‡³å°‘åº”è¯¥æœ‰ä¸€ä¸ªè¿›ç¨‹è·å–é”"
            assert successful_saves >= 1, "è‡³å°‘åº”è¯¥æœ‰ä¸€ä¸ªè¿›ç¨‹æˆåŠŸä¿å­˜"
            assert len(pins) == successful_saves, "Pinæ•°é‡åº”è¯¥ç­‰äºæˆåŠŸä¿å­˜çš„è¿›ç¨‹æ•°"
            
            print("âœ… è¿›ç¨‹ç®¡ç†å™¨é›†æˆæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ è¿›ç¨‹ç®¡ç†å™¨é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_database_optimization_effects(self) -> bool:
        """æµ‹è¯•æ•°æ®åº“ä¼˜åŒ–æ•ˆæœ"""
        print("\n=== æµ‹è¯•æ•°æ®åº“ä¼˜åŒ–æ•ˆæœ ===")
        
        db_path = os.path.join(self.test_dir, "optimization_test.db")
        
        try:
            # åˆå§‹åŒ–æ•°æ®åº“å¹¶åº”ç”¨ä¼˜åŒ–
            initialize_database(db_path)
            migrate_result = migrate_database(db_path)
            print(f"æ•°æ®åº“è¿ç§»ç»“æœ: {migrate_result}")
            
            repository = SQLiteRepository()
            
            # æµ‹è¯•å¤§é‡æ•°æ®çš„æ€§èƒ½
            test_pins = []
            for i in range(200):
                pin_data = {
                    'id': f'optimization_pin_{i}',
                    'title': f'Optimization Test Pin {i}',
                    'description': f'Testing database optimization with pin {i}',
                    'largest_image_url': f'https://example.com/opt_{i}.jpg',
                    'creator': {'id': f'creator_{i % 20}', 'name': f'Creator {i % 20}'},
                    'board': {'id': f'board_{i % 10}', 'name': f'Board {i % 10}'}
                }
                test_pins.append(pin_data)
            
            # æ‰¹é‡ä¿å­˜æ€§èƒ½æµ‹è¯•
            start_time = time.time()
            result = repository.save_pins_batch(test_pins, 'optimization_test')
            save_time = time.time() - start_time
            
            print(f"æ‰¹é‡ä¿å­˜200ä¸ªPinè€—æ—¶: {save_time:.3f}ç§’")
            print(f"å¹³å‡æ¯ä¸ªPin: {save_time/200*1000:.1f}æ¯«ç§’")
            
            # æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
            start_time = time.time()
            pins = repository.load_pins_by_query('optimization_test', limit=100)
            query_time = time.time() - start_time
            
            print(f"æŸ¥è¯¢100ä¸ªPinè€—æ—¶: {query_time:.3f}ç§’")
            print(f"æŸ¥è¯¢åˆ°çš„Pinæ•°é‡: {len(pins)}")
            
            # éªŒè¯ç»“æœ
            assert result == True, "æ‰¹é‡ä¿å­˜åº”è¯¥æˆåŠŸ"
            assert len(pins) == 100, "åº”è¯¥æŸ¥è¯¢åˆ°100ä¸ªPin"
            assert save_time < 5.0, "ä¿å­˜æ—¶é—´åº”è¯¥åœ¨åˆç†èŒƒå›´å†…"
            assert query_time < 1.0, "æŸ¥è¯¢æ—¶é—´åº”è¯¥åœ¨åˆç†èŒƒå›´å†…"
            
            print("âœ… æ•°æ®åº“ä¼˜åŒ–æ•ˆæœæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_concurrent_stress_scenario(self) -> bool:
        """æµ‹è¯•å¹¶å‘å‹åŠ›åœºæ™¯"""
        print("\n=== æµ‹è¯•å¹¶å‘å‹åŠ›åœºæ™¯ ===")
        
        db_path = os.path.join(self.test_dir, "stress_test.db")
        
        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            initialize_database(db_path)
            migrate_database(db_path)
            
            def stress_worker(worker_id):
                """å‹åŠ›æµ‹è¯•å·¥ä½œçº¿ç¨‹"""
                repository = SQLiteRepository()
                
                # æ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šç§æ“ä½œ
                operations = []
                
                # 1. æ’å…¥æ–°Pin
                for i in range(3):
                    pin_data = {
                        'id': f'stress_pin_{worker_id}_{i}',
                        'title': f'Stress Pin {worker_id}-{i}',
                        'largest_image_url': f'https://example.com/stress_{worker_id}_{i}.jpg'
                    }
                    result = repository.save_pins_batch([pin_data], 'stress_test')
                    operations.append(result)
                
                # 2. æ›´æ–°ç°æœ‰Pinï¼ˆæ¨¡æ‹Ÿé‡å¤æ•°æ®ï¼‰
                if worker_id % 2 == 0:
                    update_data = {
                        'id': f'stress_pin_{worker_id}_0',
                        'title': f'Updated Stress Pin {worker_id}-0',
                        'largest_image_url': f'https://example.com/updated_stress_{worker_id}_0.jpg'
                    }
                    result = repository.save_pins_batch([update_data], 'stress_test')
                    operations.append(result)
                
                return all(operations)
            
            # å¯åŠ¨å¤§é‡å¹¶å‘çº¿ç¨‹
            num_workers = 15
            start_time = time.time()
            
            with ThreadPoolExecutor(max_workers=num_workers) as executor:
                futures = [executor.submit(stress_worker, i) for i in range(num_workers)]
                results = [future.result() for future in futures]
            
            total_time = time.time() - start_time
            
            # éªŒè¯ç»“æœ
            repository = SQLiteRepository()
            pins = repository.load_pins_by_query('stress_test')
            
            print(f"å¹¶å‘å‹åŠ›æµ‹è¯•ç»“æœ: {sum(results)}/{len(results)} æˆåŠŸ")
            print(f"æ€»è€—æ—¶: {total_time:.3f}ç§’")
            print(f"æœ€ç»ˆPinæ•°é‡: {len(pins)}")
            
            # è®¡ç®—é¢„æœŸPinæ•°é‡ï¼šæ¯ä¸ªworker 3ä¸ªæ–°Pin + ä¸€åŠworkerçš„æ›´æ–°æ“ä½œ
            expected_pins = num_workers * 3  # æ›´æ–°æ“ä½œä¸ä¼šå¢åŠ Pinæ•°é‡
            
            assert all(results), "æ‰€æœ‰å¹¶å‘æ“ä½œéƒ½åº”è¯¥æˆåŠŸ"
            assert len(pins) == expected_pins, f"Pinæ•°é‡åº”è¯¥æ˜¯{expected_pins}"
            
            print("âœ… å¹¶å‘å‹åŠ›åœºæ™¯æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"âŒ å¹¶å‘å‹åŠ›æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


def run_integration_verification():
    """è¿è¡Œå®Œæ•´çš„é›†æˆéªŒè¯æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹Pinterest Scraper IntegrityErrorä¿®å¤éªŒè¯")
    print("=" * 60)
    
    verifier = IntegrityErrorFixVerification()
    
    try:
        success = True
        
        # æ‰§è¡Œæ‰€æœ‰éªŒè¯æµ‹è¯•
        success &= verifier.test_original_integrity_error_scenario()
        success &= verifier.test_process_manager_integration()
        success &= verifier.test_database_optimization_effects()
        success &= verifier.test_concurrent_stress_scenario()
        
        print("\n" + "=" * 60)
        
        if success:
            print("ğŸ‰ æ‰€æœ‰é›†æˆéªŒè¯æµ‹è¯•é€šè¿‡ï¼")
            print("âœ… Pinterest Scraper IntegrityErroré—®é¢˜å·²å®Œå…¨ä¿®å¤")
            print("âœ… ç³»ç»Ÿåœ¨å„ç§åœºæ™¯ä¸‹è¡¨ç°ç¨³å®š")
            print("\nğŸ“‹ ä¿®å¤æ€»ç»“:")
            print("  1. âœ… å®ç°äº†UPSERTæ“ä½œï¼Œæ¶ˆé™¤ç«æ€æ¡ä»¶")
            print("  2. âœ… æ·»åŠ äº†è¿›ç¨‹ç®¡ç†ï¼Œé˜²æ­¢å¤šå®ä¾‹å†²çª")
            print("  3. âœ… ä¼˜åŒ–äº†æ•°æ®åº“ç´¢å¼•ï¼Œæå‡æ€§èƒ½")
            print("  4. âœ… é€šè¿‡äº†å…¨é¢çš„å¹¶å‘æµ‹è¯•éªŒè¯")
            print("  5. âœ… ç³»ç»Ÿåœ¨é«˜å‹åŠ›åœºæ™¯ä¸‹ç¨³å®šè¿è¡Œ")
        else:
            print("âŒ éƒ¨åˆ†é›†æˆéªŒè¯æµ‹è¯•å¤±è´¥")
            print("éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥å’Œä¿®å¤")
            return False
        
    finally:
        verifier.cleanup_test_environment()
    
    return success


if __name__ == '__main__':
    success = run_integration_verification()
    sys.exit(0 if success else 1)
