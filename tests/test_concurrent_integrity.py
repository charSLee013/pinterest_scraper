#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å¹¶å‘å®Œæ•´æ€§æµ‹è¯•å¥—ä»¶
ä¸“é—¨æµ‹è¯•Pinterest scraperåœ¨å¹¶å‘åœºæ™¯ä¸‹çš„æ•°æ®å®Œæ•´æ€§
"""

import os
import sys
import time
import threading
import multiprocessing
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.core.database.base import initialize_database
from src.core.database.repository import SQLiteRepository
from src.core.process_manager import ProcessManager


class ConcurrentIntegrityTester:
    """å¹¶å‘å®Œæ•´æ€§æµ‹è¯•å™¨"""
    
    def __init__(self, test_name: str):
        self.test_name = test_name
        self.test_dir = f"test_concurrent_{test_name}"
        self.db_path = os.path.join(self.test_dir, f"{test_name}.db")
        self.setup_test_environment()
    
    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        os.makedirs(self.test_dir, exist_ok=True)
        
        # åˆ é™¤å·²å­˜åœ¨çš„æ•°æ®åº“æ–‡ä»¶
        if os.path.exists(self.db_path):
            try:
                os.unlink(self.db_path)
            except:
                pass
        
        # åˆå§‹åŒ–æ•°æ®åº“
        initialize_database(self.db_path)
    
    def cleanup_test_environment(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        time.sleep(0.2)  # ç­‰å¾…è¿æ¥å…³é—­
        try:
            if os.path.exists(self.db_path):
                os.unlink(self.db_path)
            if os.path.exists(self.test_dir):
                os.rmdir(self.test_dir)
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†æµ‹è¯•ç¯å¢ƒå¤±è´¥: {e}")
    
    def test_concurrent_same_pin_upsert(self, num_threads: int = 10) -> bool:
        """æµ‹è¯•å¹¶å‘æ’å…¥ç›¸åŒPinçš„UPSERTè¡Œä¸º"""
        print(f"\n=== æµ‹è¯•å¹¶å‘ç›¸åŒPin UPSERT ({num_threads}çº¿ç¨‹) ===")
        
        def worker(worker_id):
            """å·¥ä½œçº¿ç¨‹ï¼šå°è¯•æ’å…¥ç›¸åŒçš„Pin"""
            repository = SQLiteRepository()
            
            pin_data = {
                'id': 'same_pin_test',
                'title': f'Worker {worker_id} Title',
                'description': f'Worker {worker_id} Description',
                'largest_image_url': 'https://example.com/same_pin.jpg',
                'stats': {'saves': worker_id * 10}
            }
            
            start_time = time.time()
            result = repository.save_pins_batch([pin_data], 'concurrent_same_pin')
            elapsed = time.time() - start_time
            
            print(f"Worker {worker_id} å®Œæˆï¼Œè€—æ—¶: {elapsed:.3f}ç§’ï¼Œç»“æœ: {result}")
            return result
        
        # å¯åŠ¨å¤šä¸ªçº¿ç¨‹åŒæ—¶æ’å…¥ç›¸åŒPin
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(worker, i) for i in range(num_threads)]
            results = [future.result() for future in futures]
        
        # éªŒè¯ç»“æœ
        repository = SQLiteRepository()
        pins = repository.load_pins_by_query('concurrent_same_pin')
        
        print(f"å¹¶å‘æ’å…¥ç»“æœ: {results}")
        print(f"æœ€ç»ˆPinæ•°é‡: {len(pins)}")
        if pins:
            print(f"æœ€ç»ˆPinæ ‡é¢˜: {pins[0]['title']}")
        
        # éªŒè¯ï¼šæ‰€æœ‰æ“ä½œéƒ½æˆåŠŸï¼Œä½†åªæœ‰ä¸€ä¸ªPin
        assert all(results), "æ‰€æœ‰UPSERTæ“ä½œéƒ½åº”è¯¥æˆåŠŸ"
        assert len(pins) == 1, "åº”è¯¥åªæœ‰ä¸€ä¸ªPinï¼ˆå»é‡æˆåŠŸï¼‰"
        
        print("âœ… å¹¶å‘ç›¸åŒPin UPSERTæµ‹è¯•é€šè¿‡")
        return True
    
    def test_concurrent_different_pins(self, num_threads: int = 10) -> bool:
        """æµ‹è¯•å¹¶å‘æ’å…¥ä¸åŒPin"""
        print(f"\n=== æµ‹è¯•å¹¶å‘ä¸åŒPinæ’å…¥ ({num_threads}çº¿ç¨‹) ===")
        
        def worker(worker_id):
            """å·¥ä½œçº¿ç¨‹ï¼šæ’å…¥ä¸åŒçš„Pin"""
            repository = SQLiteRepository()
            
            pin_data = {
                'id': f'different_pin_{worker_id}',
                'title': f'Different Pin {worker_id}',
                'largest_image_url': f'https://example.com/different_{worker_id}.jpg'
            }
            
            return repository.save_pins_batch([pin_data], 'concurrent_different_pins')
        
        # å¯åŠ¨å¤šä¸ªçº¿ç¨‹æ’å…¥ä¸åŒPin
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(worker, i) for i in range(num_threads)]
            results = [future.result() for future in futures]
        
        # éªŒè¯ç»“æœ
        repository = SQLiteRepository()
        pins = repository.load_pins_by_query('concurrent_different_pins')
        
        print(f"å¹¶å‘æ’å…¥ç»“æœ: {results}")
        print(f"æœ€ç»ˆPinæ•°é‡: {len(pins)}")
        
        # éªŒè¯ï¼šæ‰€æœ‰æ“ä½œéƒ½æˆåŠŸï¼Œæœ‰å¯¹åº”æ•°é‡çš„Pin
        assert all(results), "æ‰€æœ‰æ’å…¥æ“ä½œéƒ½åº”è¯¥æˆåŠŸ"
        assert len(pins) == num_threads, f"åº”è¯¥æœ‰{num_threads}ä¸ªä¸åŒçš„Pin"
        
        print("âœ… å¹¶å‘ä¸åŒPinæ’å…¥æµ‹è¯•é€šè¿‡")
        return True
    
    def test_concurrent_mixed_operations(self, num_threads: int = 8) -> bool:
        """æµ‹è¯•å¹¶å‘æ··åˆæ“ä½œï¼ˆæ’å…¥+æ›´æ–°ï¼‰"""
        print(f"\n=== æµ‹è¯•å¹¶å‘æ··åˆæ“ä½œ ({num_threads}çº¿ç¨‹) ===")
        
        # å…ˆæ’å…¥ä¸€äº›åŸºç¡€æ•°æ®
        repository = SQLiteRepository()
        base_pins = []
        for i in range(5):
            pin_data = {
                'id': f'mixed_pin_{i}',
                'title': f'Base Pin {i}',
                'largest_image_url': f'https://example.com/base_{i}.jpg'
            }
            base_pins.append(pin_data)
        
        repository.save_pins_batch(base_pins, 'concurrent_mixed')
        print(f"é¢„æ’å…¥åŸºç¡€æ•°æ®: {len(base_pins)} ä¸ªPin")
        
        def worker(worker_id):
            """å·¥ä½œçº¿ç¨‹ï¼šæ‰§è¡Œæ··åˆæ“ä½œ"""
            repository = SQLiteRepository()
            
            if worker_id % 2 == 0:
                # å¶æ•°çº¿ç¨‹ï¼šæ›´æ–°ç°æœ‰Pin
                pin_id = f'mixed_pin_{worker_id % 5}'
                pin_data = {
                    'id': pin_id,
                    'title': f'Updated by Worker {worker_id}',
                    'largest_image_url': f'https://example.com/updated_{worker_id}.jpg'
                }
            else:
                # å¥‡æ•°çº¿ç¨‹ï¼šæ’å…¥æ–°Pin
                pin_data = {
                    'id': f'new_mixed_pin_{worker_id}',
                    'title': f'New Pin by Worker {worker_id}',
                    'largest_image_url': f'https://example.com/new_{worker_id}.jpg'
                }
            
            return repository.save_pins_batch([pin_data], 'concurrent_mixed')
        
        # å¯åŠ¨æ··åˆæ“ä½œ
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(worker, i) for i in range(num_threads)]
            results = [future.result() for future in futures]
        
        # éªŒè¯ç»“æœ
        pins = repository.load_pins_by_query('concurrent_mixed')
        
        print(f"æ··åˆæ“ä½œç»“æœ: {results}")
        print(f"æœ€ç»ˆPinæ•°é‡: {len(pins)}")
        
        # è®¡ç®—é¢„æœŸæ•°é‡ï¼š5ä¸ªåŸºç¡€ + 4ä¸ªæ–°å¢ï¼ˆå¥‡æ•°çº¿ç¨‹ï¼‰
        expected_count = 5 + (num_threads // 2)
        
        assert all(results), "æ‰€æœ‰æ··åˆæ“ä½œéƒ½åº”è¯¥æˆåŠŸ"
        assert len(pins) == expected_count, f"åº”è¯¥æœ‰{expected_count}ä¸ªPin"
        
        print("âœ… å¹¶å‘æ··åˆæ“ä½œæµ‹è¯•é€šè¿‡")
        return True
    
    def test_process_manager_concurrent_access(self) -> bool:
        """æµ‹è¯•è¿›ç¨‹ç®¡ç†å™¨çš„å¹¶å‘è®¿é—®"""
        print(f"\n=== æµ‹è¯•è¿›ç¨‹ç®¡ç†å™¨å¹¶å‘è®¿é—® ===")
        
        def worker(worker_id):
            """å·¥ä½œè¿›ç¨‹ï¼šå°è¯•è·å–è¿›ç¨‹é”"""
            manager = ProcessManager(f"concurrent_process_test", self.test_dir)
            
            start_time = time.time()
            result = manager.acquire_lock()
            
            if result:
                print(f"Worker {worker_id} è·å–é”æˆåŠŸ")
                time.sleep(0.1)  # æ¨¡æ‹Ÿå·¥ä½œ
                manager.release_lock()
                print(f"Worker {worker_id} é‡Šæ”¾é”")
                return True
            else:
                print(f"Worker {worker_id} è·å–é”å¤±è´¥")
                return False
        
        # å¯åŠ¨å¤šä¸ªçº¿ç¨‹å°è¯•è·å–é”
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(worker, i) for i in range(5)]
            results = [future.result() for future in futures]
        
        print(f"è¿›ç¨‹é”è·å–ç»“æœ: {results}")
        
        # éªŒè¯ï¼šè‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸè·å–é”
        success_count = sum(results)
        print(f"æˆåŠŸè·å–é”çš„çº¿ç¨‹æ•°: {success_count}")
        
        assert success_count >= 1, "è‡³å°‘åº”è¯¥æœ‰ä¸€ä¸ªçº¿ç¨‹æˆåŠŸè·å–é”"
        
        print("âœ… è¿›ç¨‹ç®¡ç†å™¨å¹¶å‘è®¿é—®æµ‹è¯•é€šè¿‡")
        return True


def test_high_concurrency_stress():
    """é«˜å¹¶å‘å‹åŠ›æµ‹è¯•"""
    print("\n=== é«˜å¹¶å‘å‹åŠ›æµ‹è¯• ===")
    
    tester = ConcurrentIntegrityTester("stress_test")
    
    try:
        def stress_worker(worker_id):
            """å‹åŠ›æµ‹è¯•å·¥ä½œçº¿ç¨‹"""
            repository = SQLiteRepository()
            
            # æ¯ä¸ªçº¿ç¨‹æ’å…¥å¤šä¸ªPin
            pins = []
            for i in range(5):
                pin_data = {
                    'id': f'stress_pin_{worker_id}_{i}',
                    'title': f'Stress Pin {worker_id}-{i}',
                    'largest_image_url': f'https://example.com/stress_{worker_id}_{i}.jpg'
                }
                pins.append(pin_data)
            
            return repository.save_pins_batch(pins, 'stress_test')
        
        # å¯åŠ¨å¤§é‡çº¿ç¨‹
        num_threads = 20
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = [executor.submit(stress_worker, i) for i in range(num_threads)]
            results = [future.result() for future in futures]
        
        total_time = time.time() - start_time
        
        # éªŒè¯ç»“æœ
        repository = SQLiteRepository()
        pins = repository.load_pins_by_query('stress_test')
        
        print(f"å‹åŠ›æµ‹è¯•ç»“æœ: {sum(results)}/{len(results)} æˆåŠŸ")
        print(f"æ€»è€—æ—¶: {total_time:.3f}ç§’")
        print(f"æœ€ç»ˆPinæ•°é‡: {len(pins)}")
        print(f"é¢„æœŸPinæ•°é‡: {num_threads * 5}")
        
        assert all(results), "æ‰€æœ‰å‹åŠ›æµ‹è¯•æ“ä½œéƒ½åº”è¯¥æˆåŠŸ"
        assert len(pins) == num_threads * 5, "Pinæ•°é‡åº”è¯¥æ­£ç¡®"
        
        print("âœ… é«˜å¹¶å‘å‹åŠ›æµ‹è¯•é€šè¿‡")
        return True
        
    finally:
        tester.cleanup_test_environment()


if __name__ == '__main__':
    print("å¼€å§‹å¹¶å‘å®Œæ•´æ€§æµ‹è¯•...")
    
    success = True
    
    # æµ‹è¯•1ï¼šå¹¶å‘ç›¸åŒPin UPSERT
    tester1 = ConcurrentIntegrityTester("same_pin")
    try:
        success &= tester1.test_concurrent_same_pin_upsert(10)
    finally:
        tester1.cleanup_test_environment()
    
    # æµ‹è¯•2ï¼šå¹¶å‘ä¸åŒPinæ’å…¥
    tester2 = ConcurrentIntegrityTester("different_pins")
    try:
        success &= tester2.test_concurrent_different_pins(10)
    finally:
        tester2.cleanup_test_environment()
    
    # æµ‹è¯•3ï¼šå¹¶å‘æ··åˆæ“ä½œ
    tester3 = ConcurrentIntegrityTester("mixed_ops")
    try:
        success &= tester3.test_concurrent_mixed_operations(8)
    finally:
        tester3.cleanup_test_environment()
    
    # æµ‹è¯•4ï¼šè¿›ç¨‹ç®¡ç†å™¨å¹¶å‘è®¿é—®
    tester4 = ConcurrentIntegrityTester("process_manager")
    try:
        success &= tester4.test_process_manager_concurrent_access()
    finally:
        tester4.cleanup_test_environment()
    
    # æµ‹è¯•5ï¼šé«˜å¹¶å‘å‹åŠ›æµ‹è¯•
    success &= test_high_concurrency_stress()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰å¹¶å‘å®Œæ•´æ€§æµ‹è¯•é€šè¿‡ï¼")
        print("âœ… Pinterest scraperå·²æˆåŠŸä¿®å¤IntegrityErroré—®é¢˜")
        print("âœ… ç³»ç»Ÿåœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹è¡¨ç°ç¨³å®š")
    else:
        print("\nâŒ éƒ¨åˆ†å¹¶å‘æµ‹è¯•å¤±è´¥")
        sys.exit(1)
